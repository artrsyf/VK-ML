{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\artrsyf\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from scipy.sparse import hstack\n",
    "import tldextract\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import warnings\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "nltk.download('stopwords')\n",
    "stop_words = stopwords.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>m.kp.md</td>\n",
       "      <td>Экс-министр экономики Молдовы - главе МИДЭИ, ц...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>www.kp.by</td>\n",
       "      <td>Эта песня стала известна многим телезрителям б...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>fanserials.tv</td>\n",
       "      <td>Банши 4 сезон 2 серия Бремя красоты смотреть о...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>colorbox.spb.ru</td>\n",
       "      <td>Не Беси Меня Картинки</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>tula-sport.ru</td>\n",
       "      <td>В Новомосковске сыграют следж-хоккеисты алекси...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID              url                                              title  \\\n",
       "0   0          m.kp.md  Экс-министр экономики Молдовы - главе МИДЭИ, ц...   \n",
       "1   1        www.kp.by  Эта песня стала известна многим телезрителям б...   \n",
       "2   2    fanserials.tv  Банши 4 сезон 2 серия Бремя красоты смотреть о...   \n",
       "3   3  colorbox.spb.ru                              Не Беси Меня Картинки   \n",
       "4   4    tula-sport.ru  В Новомосковске сыграют следж-хоккеисты алекси...   \n",
       "\n",
       "   label  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(\"test.csv\")\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Простое решение с использованием LabelEncoder для категориальных признаков:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Просто используем LabelEncoder для категориальных признаков и применяем логистическую регрессию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93    118594\n",
      "           1       0.00      0.00      0.00     16715\n",
      "\n",
      "    accuracy                           0.88    135309\n",
      "   macro avg       0.44      0.50      0.47    135309\n",
      "weighted avg       0.77      0.88      0.82    135309\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv(\"test.csv\")\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "\n",
    "y_train = train_df[\"label\"]\n",
    "x_train = train_df.drop(\"label\", axis=1)\n",
    "x_test = test_df\n",
    "\n",
    "le = LabelEncoder()\n",
    "categorical_features = x_train.select_dtypes(include=[object]).columns.tolist()\n",
    "for feature in categorical_features:\n",
    "    x_train[feature] = le.fit_transform(x_train[feature])\n",
    "    x_test[feature] = le.fit_transform(x_test[feature])\n",
    "    \n",
    "model = LogisticRegression()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "print(classification_report(y_train, model.predict(x_train)))\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "x_test[\"label\"] = y_pred\n",
    "x_test[[\"ID\", \"label\"]].to_csv(\"simple_baseline.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Микровывод:**\n",
    "<br>\n",
    "Score модели 0.Из решения видно, что модель работает некорректно и определяет все значения к классу 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Рассмотрим теперь распределение значений датасета "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([118594,  16715], dtype=int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df[\"label\"].unique() # Только значения 0 и 1\n",
    "distribution_stats = train_df[\"label\"].value_counts()\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Site distribution\")\n",
    "plt.bar(x=['0', '1'], height=distribution_stats.values)\n",
    "distribution_stats.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Микровывод:**\n",
    "<br>\n",
    "Из диаграммы видим, что в датасете большой перекос в сторону не порнографических сайтов. Очевидно, что нужно обучать модель на сбалансированной выборке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Воспользуемся простым решением с TfidfVectorizer, применив эмбеддинг только к одной фиче"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99     29563\n",
      "           1       0.99      0.81      0.89      4264\n",
      "\n",
      "    accuracy                           0.98     33827\n",
      "   macro avg       0.98      0.91      0.94     33827\n",
      "weighted avg       0.98      0.98      0.97     33827\n",
      "\n",
      "[[29543    20]\n",
      " [  806  3458]]\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv(\"test.csv\")\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "\n",
    "train_df = train_df.dropna()\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "num_features = tfidf_vectorizer.fit_transform(train_df['title'])\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(num_features, train_df[\"label\"], test_size=0.25)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(x_train, y_train)\n",
    "print(classification_report(y_valid, model.predict(x_valid)))\n",
    "print(confusion_matrix(y_valid, model.predict(x_valid)))\n",
    "\n",
    "y_pred = model.predict(tfidf_vectorizer.transform(test_df['title']))\n",
    "test_df[\"label\"] = y_pred\n",
    "test_df[[\"ID\", \"label\"]].to_csv(\"ml_baseline.csv\", index=False) # score 0.9142504626773597"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Микровывод:**\n",
    "<br>\n",
    "Score модели 9142504626773597. Модель показала хороший результат, но виден перекос в предсказаниях в сторону класса 0. Чтобы это исправить, попробуем сбалансировать по классам датасет\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучаем модель на сбалансированной выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     29676\n",
      "           1       0.96      0.93      0.95      4151\n",
      "\n",
      "    accuracy                           0.99     33827\n",
      "   macro avg       0.98      0.96      0.97     33827\n",
      "weighted avg       0.99      0.99      0.99     33827\n",
      "\n",
      "[[29518   158]\n",
      " [  279  3872]]\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv(\"test.csv\")\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "\n",
    "train_df = train_df.dropna()\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "num_features = tfidf_vectorizer.fit_transform(train_df['title'])\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(num_features, train_df[\"label\"], test_size=0.25)\n",
    "\n",
    "model = LogisticRegression(class_weight='balanced')\n",
    "model.fit(x_train, y_train)\n",
    "print(classification_report(y_valid, model.predict(x_valid)))\n",
    "print(confusion_matrix(y_valid, model.predict(x_valid)))\n",
    "\n",
    "y_pred = model.predict(tfidf_vectorizer.transform(test_df['title']))\n",
    "test_df[\"label\"] = y_pred\n",
    "test_df[[\"ID\", \"label\"]].to_csv(\"ml_baseline.csv\", index=False) # score 0.9438922204879652"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Микровывод:**\n",
    "<br>\n",
    "Score модели 0.9438922204879652. Видно, что количество ошибок по классам +- уравнялось, результат модели также улучшился"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим также работу модели по фиче url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.97     29673\n",
      "           1       0.76      0.94      0.84      4154\n",
      "\n",
      "    accuracy                           0.96     33827\n",
      "   macro avg       0.88      0.95      0.91     33827\n",
      "weighted avg       0.96      0.96      0.96     33827\n",
      "\n",
      "[[28465  1208]\n",
      " [  256  3898]]\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv(\"test.csv\")\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "\n",
    "train_df = train_df.dropna()\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "url_features = tfidf_vectorizer.fit_transform(train_df['url'])\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(url_features, train_df[\"label\"], test_size=0.25)\n",
    "\n",
    "model = LogisticRegression(class_weight='balanced', max_iter=1000)\n",
    "model.fit(x_train, y_train)\n",
    "print(classification_report(y_valid, model.predict(x_valid)))\n",
    "print(confusion_matrix(y_valid, model.predict(x_valid)))\n",
    "\n",
    "y_pred = model.predict(tfidf_vectorizer.transform(test_df['url']))\n",
    "test_df[\"label\"] = y_pred\n",
    "test_df[[\"ID\", \"label\"]].to_csv(\"ml_baseline.csv\", index=False) # score 0.8335864612714254"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Микровывод:**\n",
    "<br>\n",
    "Score модели 0.8335864612714254. Результат сильно упал, значит, фича url менее информативная в сравнении с title\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Попробуем теперь построить модель, используя оба категориальных признака"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном решении отдельно ставим в соответствие вектор для url и title. Далее эти вектора стекируем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     29628\n",
      "           1       0.98      0.96      0.97      4199\n",
      "\n",
      "    accuracy                           0.99     33827\n",
      "   macro avg       0.99      0.98      0.98     33827\n",
      "weighted avg       0.99      0.99      0.99     33827\n",
      "\n",
      "[[29541    87]\n",
      " [  147  4052]]\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv(\"test.csv\")\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "\n",
    "train_df = train_df.dropna()\n",
    "\n",
    "tfidf_vectorizer1 = TfidfVectorizer()\n",
    "tfidf_vectorizer2 = TfidfVectorizer()\n",
    "\n",
    "title_features = tfidf_vectorizer1.fit_transform(train_df['title'])\n",
    "url_features = tfidf_vectorizer2.fit_transform(train_df['url'])\n",
    "combined_features = hstack([title_features, url_features])\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(combined_features, train_df[\"label\"], test_size=0.25)\n",
    "\n",
    "model = LogisticRegression(class_weight='balanced', max_iter=1000)\n",
    "model.fit(x_train, y_train)\n",
    "print(classification_report(y_valid, model.predict(x_valid)))\n",
    "print(confusion_matrix(y_valid, model.predict(x_valid)))\n",
    "\n",
    "combined_test_result = hstack([tfidf_vectorizer1.transform(test_df['title']), tfidf_vectorizer2.transform(test_df['url'])])\n",
    "y_pred = model.predict(combined_test_result)\n",
    "test_df[\"label\"] = y_pred\n",
    "test_df[[\"ID\", \"label\"]].to_csv(\"ml_baseline.csv\", index=False) # score 0.9351205583756346"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Микровывод:**\n",
    "<br>\n",
    "Score модели 0.9351205583756346. Как видно из результата, стекирование эмбеддингов пользы не принесло. Скорее всего модель немного переобучилась из- за большого количества параметров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь попробуем использовать эмбеддинг конкатенации строк из url и title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     29617\n",
      "           1       0.96      0.95      0.95      4210\n",
      "\n",
      "    accuracy                           0.99     33827\n",
      "   macro avg       0.98      0.97      0.97     33827\n",
      "weighted avg       0.99      0.99      0.99     33827\n",
      "\n",
      "[[29454   163]\n",
      " [  223  3987]]\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv(\"test.csv\")\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "\n",
    "train_df = train_df.dropna()\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "url_features = tfidf_vectorizer.fit_transform(train_df['title'] + train_df['url'])\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(url_features, train_df[\"label\"], test_size=0.25)\n",
    "\n",
    "model = LogisticRegression(class_weight='balanced', max_iter=1000)\n",
    "model.fit(x_train, y_train)\n",
    "print(classification_report(y_valid, model.predict(x_valid)))\n",
    "print(confusion_matrix(y_valid, model.predict(x_valid)))\n",
    "\n",
    "y_pred = model.predict(tfidf_vectorizer.transform(test_df['title'] + test_df['url']))\n",
    "test_df[\"label\"] = y_pred\n",
    "test_df[[\"ID\", \"label\"]].to_csv(\"ml_baseline.csv\", index=False) # score 0.9352861577648651"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Микровывод:**\n",
    "<br>\n",
    "Score модели 0.9351205583756346. Результата также нет"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Решенеи с использованием TfidfVectorizer для url и CountVectorizer для title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CountVectorizer - хорошее решение для title, т.к. title легко разбить на слова, а также можно выкинуть стоп-слова.\n",
    "<br>\n",
    "Для url оставим TfidfVectorizer\n",
    "<br>\n",
    "Также в данной функции в зависимости от параметра validation либо используется валидационная выборка с анализом результатов, либо нет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictPipeline(train_path, test_path, target, validation=False):\n",
    "    transformer = ColumnTransformer([\n",
    "        (\"tfidf\", TfidfVectorizer(), \"url\"),\n",
    "        (\"count\", CountVectorizer(stop_words=stop_words), \"title\"),\n",
    "    ])\n",
    "    pipeline = Pipeline([\n",
    "        (\"preprocessor\", transformer),\n",
    "        (\"model\", LogisticRegression(class_weight='balanced', max_iter=1000))\n",
    "    ])\n",
    "\n",
    "    test_df = pd.read_csv(test_path)\n",
    "    train_df = pd.read_csv(train_path)\n",
    "\n",
    "    train_df = train_df.dropna()\n",
    "\n",
    "    x_train = train_df\n",
    "    y_train = train_df[target]\n",
    "    del x_train[target]\n",
    "    del x_train[\"ID\"]\n",
    "\n",
    "    if validation:\n",
    "        x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.25)\n",
    "\n",
    "    pipeline.fit(x_train, y_train)\n",
    "    predicts = pipeline.predict(test_df)\n",
    "\n",
    "    if validation:\n",
    "        validation_predicts = pipeline.predict(x_valid)\n",
    "        print(classification_report(y_valid, validation_predicts))\n",
    "        print(confusion_matrix(y_valid, validation_predicts))\n",
    "        x_valid[\"true_label\"] = y_valid\n",
    "        x_valid[\"predicted_label\"] = validation_predicts\n",
    "        return x_valid\n",
    "\n",
    "    test_df[target] = predicts\n",
    "    test_df[[\"ID\", target]].to_csv(\"ml_baseline.csv\", index=False) # score 0.9573121246550884\n",
    "\n",
    "predictPipeline(\"train.csv\", \"test.csv\", \"label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Микровывод:**\n",
    "<br>\n",
    "Score модели 0.9573121246550884. Видно, что использование CountVectorizer с учетом выброса стоп-слов улучшило результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     29676\n",
      "           1       0.94      0.96      0.95      4151\n",
      "\n",
      "    accuracy                           0.99     33827\n",
      "   macro avg       0.97      0.98      0.97     33827\n",
      "weighted avg       0.99      0.99      0.99     33827\n",
      "\n",
      "[[29436   240]\n",
      " [  157  3994]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>true_label</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>849</th>\n",
       "      <td>folksland.net</td>\n",
       "      <td>Как грамотно расставить мебель в маленькой кух...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20405</th>\n",
       "      <td>surfthespear.com</td>\n",
       "      <td>Tristan Thompson thanks his fans | SurfTheSpea...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5986</th>\n",
       "      <td>antyseptyky.com</td>\n",
       "      <td>відсотків —</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31697</th>\n",
       "      <td>arhles.net</td>\n",
       "      <td>Уголок</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66069</th>\n",
       "      <td>m.xn----8sbp3abdbfk9f.com</td>\n",
       "      <td>Рогоносец вылизал анус женушке, а та потрахала...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13662</th>\n",
       "      <td>gayrawclub.com</td>\n",
       "      <td>Pierre Fitch Knock Out DF.AF,RG » Gay Raw Club</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119541</th>\n",
       "      <td>video.brus.club</td>\n",
       "      <td>MAINE MENDOZA, NAPAKALUHO RAW! MGA FANS TO THE...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102476</th>\n",
       "      <td>onlineporno.vip</td>\n",
       "      <td>Сама напросилась на реально жаркий и мощный ра...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114666</th>\n",
       "      <td>intsport.net</td>\n",
       "      <td>Кубок остаётся без «Заречья». А может, и без «...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126974</th>\n",
       "      <td>suj.ru</td>\n",
       "      <td>Смотреть бесплатно Воображаемые друзья подсказ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>397 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              url  \\\n",
       "849                 folksland.net   \n",
       "20405            surfthespear.com   \n",
       "5986              antyseptyky.com   \n",
       "31697                  arhles.net   \n",
       "66069   m.xn----8sbp3abdbfk9f.com   \n",
       "...                           ...   \n",
       "13662              gayrawclub.com   \n",
       "119541            video.brus.club   \n",
       "102476            onlineporno.vip   \n",
       "114666               intsport.net   \n",
       "126974                     suj.ru   \n",
       "\n",
       "                                                    title  true_label  \\\n",
       "849     Как грамотно расставить мебель в маленькой кух...           0   \n",
       "20405   Tristan Thompson thanks his fans | SurfTheSpea...           0   \n",
       "5986                                          відсотків —           0   \n",
       "31697                                              Уголок           0   \n",
       "66069   Рогоносец вылизал анус женушке, а та потрахала...           1   \n",
       "...                                                   ...         ...   \n",
       "13662      Pierre Fitch Knock Out DF.AF,RG » Gay Raw Club           0   \n",
       "119541  MAINE MENDOZA, NAPAKALUHO RAW! MGA FANS TO THE...           0   \n",
       "102476  Сама напросилась на реально жаркий и мощный ра...           1   \n",
       "114666  Кубок остаётся без «Заречья». А может, и без «...           0   \n",
       "126974  Смотреть бесплатно Воображаемые друзья подсказ...           1   \n",
       "\n",
       "        predicted_label  \n",
       "849                   1  \n",
       "20405                 1  \n",
       "5986                  1  \n",
       "31697                 1  \n",
       "66069                 0  \n",
       "...                 ...  \n",
       "13662                 1  \n",
       "119541                1  \n",
       "102476                0  \n",
       "114666                1  \n",
       "126974                0  \n",
       "\n",
       "[397 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = predictPipeline(\"train.csv\", \"test.csv\", \"label\", validation=True)\n",
    "incorrect_predictions = result_df[(result_df['true_label'] != result_df['predicted_label'])]\n",
    "incorrect_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем отредактировать параметр url и сделать его более информативным.\n",
    "<br>\n",
    "Для этого оставим только доменное имя сайта, чтобы модель не искала лишних взаимосвязей.\n",
    "<br>\n",
    "<br>\n",
    "Также подберем с помощью GridSearchCV оптимальные гиперпараметры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tldextract\n",
    "\n",
    "def extract_domain(url):\n",
    "    return tldextract.extract(url).domain\n",
    "\n",
    "def predictPipelineWithExtractedDomain(train_path, test_path, target, validation=False, find_best_params=False):\n",
    "    transformer = ColumnTransformer([\n",
    "        (\"tfidf\", TfidfVectorizer(min_df=1, max_df=0.5), \"domain\"),\n",
    "        (\"count\", CountVectorizer(stop_words=stop_words), \"title\"),\n",
    "    ])\n",
    "    pipeline = Pipeline([\n",
    "        (\"preprocessor\", transformer),\n",
    "        (\"model\", LogisticRegression(class_weight='balanced', max_iter=1000))\n",
    "    ])\n",
    "\n",
    "    test_df = pd.read_csv(test_path)\n",
    "    train_df = pd.read_csv(train_path)\n",
    "    test_df['domain'] = test_df['url'].apply(extract_domain)\n",
    "    train_df['domain'] = train_df['url'].apply(extract_domain)\n",
    "\n",
    "    train_df = train_df.dropna()\n",
    "\n",
    "    x_train = train_df\n",
    "    y_train = train_df[target]\n",
    "    del x_train[target]\n",
    "    del x_train[\"ID\"]\n",
    "\n",
    "    if validation:\n",
    "        x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.25)\n",
    "\n",
    "\n",
    "    if find_best_params:\n",
    "        param_grid = {\n",
    "            'preprocessor__tfidf__ngram_range': [(1, 3), (4, 6), (4, 8)],\n",
    "            'preprocessor__tfidf__min_df': [1, 2, 4],\n",
    "            'preprocessor__tfidf__max_df': [0.5, 0.7, 1.0]\n",
    "        }\n",
    "    \n",
    "        grid_search = GridSearchCV(pipeline, param_grid, cv=3, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "        grid_search.fit(x_train, y_train)\n",
    "\n",
    "        print(\"Best parameters found on cross-validation set:\")\n",
    "        print(grid_search.best_params_)\n",
    "        print(\"Best cross-validation score:\")\n",
    "        print(grid_search.best_score_)\n",
    "\n",
    "    pipeline.fit(x_train, y_train)\n",
    "    predicts = pipeline.predict(test_df)\n",
    "\n",
    "    if validation:\n",
    "        validation_predicts = pipeline.predict(x_valid)\n",
    "        print(classification_report(y_valid, validation_predicts))\n",
    "        print(confusion_matrix(y_valid, validation_predicts))\n",
    "        x_valid[\"true_label\"] = y_valid\n",
    "        x_valid[\"predicted_label\"] = validation_predicts\n",
    "        return x_valid\n",
    "\n",
    "    test_df[target] = predicts\n",
    "    test_df[[\"ID\", target]].to_csv(\"ml_baseline.csv\", index=False) # score 0.9724997935419936\n",
    "\n",
    "# predictPipelineWithExtractedDomain(\"train.csv\", \"test.csv\", \"label\", find_best_params=True)\n",
    "predictPipelineWithExtractedDomain(\"train.csv\", \"test.csv\", \"label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Микровывод:**\n",
    "<br>\n",
    "Score модели 0.9724997935419936. Для модели подобраны оптимальные гиперпараметры, также поле url стало более информативным для модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также попробуем вариант с кросс-валидацией. Будем использовать 15 фолдов и 15 моделей, соответственно. Результат возьмем как среднее работы всех моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble(X, y, x_res, fold_number: int = 2, model=LogisticRegression()):\n",
    "    kf = KFold(n_splits=fold_number, shuffle=True, random_state=42)\n",
    "    a = []\n",
    "    for train_index, test_index in kf.split(X, y):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        model.fit(X_train, y_train)\n",
    "        probabilities = model.predict_proba(x_res)\n",
    "        a.append(probabilities)\n",
    "    y_pred = (np.mean(a, axis=0)[:, 1] > 0.5).astype(int)\n",
    "    return y_pred\n",
    "\n",
    "\n",
    "transformer = ColumnTransformer([\n",
    "    (\"tfidf\", TfidfVectorizer(), \"url\"),\n",
    "    (\"count\", CountVectorizer(stop_words=stop_words), \"title\"),\n",
    "])\n",
    "pipeline = Pipeline([\n",
    "    (\"preprocessor\", transformer),\n",
    "    (\"model\", LogisticRegression(class_weight='balanced', max_iter=1000))\n",
    "])\n",
    "\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "\n",
    "train_df = train_df.dropna()\n",
    "\n",
    "x_train = train_df\n",
    "y_train = train_df[\"label\"]\n",
    "del x_train[\"label\"]\n",
    "del x_train[\"ID\"]\n",
    "\n",
    "y_pred = ensemble(x_train, y_train, test_df, 25, pipeline)\n",
    "\n",
    "test_df[\"label\"] = y_pred\n",
    "test_df[[\"ID\", \"label\"]].to_csv(\"ml_baseline.csv\", index=False) # score 0.9569875020288914"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Микровывод:**\n",
    "<br>\n",
    "Score модели 0.9569875020288914. Данный способ результата не принес, из этого можно сделать вывод, что модели обучаются +- одинаково и никак не дополняют друг друга\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем использовать более точную реализацию логистической регрессии CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.083755\n",
      "0:\tlearn: 0.6027330\ttotal: 576ms\tremaining: 9m 35s\n",
      "1:\tlearn: 0.5390817\ttotal: 950ms\tremaining: 7m 53s\n",
      "2:\tlearn: 0.4999958\ttotal: 1.32s\tremaining: 7m 17s\n",
      "3:\tlearn: 0.4718684\ttotal: 1.7s\tremaining: 7m 2s\n",
      "4:\tlearn: 0.4501716\ttotal: 2.1s\tremaining: 6m 57s\n",
      "5:\tlearn: 0.4343968\ttotal: 2.46s\tremaining: 6m 47s\n",
      "6:\tlearn: 0.4162229\ttotal: 2.83s\tremaining: 6m 40s\n",
      "7:\tlearn: 0.4028474\ttotal: 3.19s\tremaining: 6m 35s\n",
      "8:\tlearn: 0.3931730\ttotal: 3.57s\tremaining: 6m 33s\n",
      "9:\tlearn: 0.3828974\ttotal: 3.94s\tremaining: 6m 30s\n",
      "10:\tlearn: 0.3752000\ttotal: 4.31s\tremaining: 6m 27s\n",
      "11:\tlearn: 0.3667644\ttotal: 4.68s\tremaining: 6m 25s\n",
      "12:\tlearn: 0.3594311\ttotal: 5.05s\tremaining: 6m 23s\n",
      "13:\tlearn: 0.3525812\ttotal: 5.42s\tremaining: 6m 21s\n",
      "14:\tlearn: 0.3450572\ttotal: 5.79s\tremaining: 6m 19s\n",
      "15:\tlearn: 0.3396238\ttotal: 6.15s\tremaining: 6m 18s\n",
      "16:\tlearn: 0.3343562\ttotal: 6.53s\tremaining: 6m 17s\n",
      "17:\tlearn: 0.3294110\ttotal: 6.89s\tremaining: 6m 16s\n",
      "18:\tlearn: 0.3238883\ttotal: 7.25s\tremaining: 6m 14s\n",
      "19:\tlearn: 0.3205005\ttotal: 7.61s\tremaining: 6m 12s\n",
      "20:\tlearn: 0.3156364\ttotal: 7.97s\tremaining: 6m 11s\n",
      "21:\tlearn: 0.3106452\ttotal: 8.34s\tremaining: 6m 10s\n",
      "22:\tlearn: 0.3069684\ttotal: 8.7s\tremaining: 6m 9s\n",
      "23:\tlearn: 0.3040024\ttotal: 9.05s\tremaining: 6m 8s\n",
      "24:\tlearn: 0.3008200\ttotal: 9.42s\tremaining: 6m 7s\n",
      "25:\tlearn: 0.2975553\ttotal: 9.78s\tremaining: 6m 6s\n",
      "26:\tlearn: 0.2942855\ttotal: 10.1s\tremaining: 6m 5s\n",
      "27:\tlearn: 0.2921996\ttotal: 10.5s\tremaining: 6m 4s\n",
      "28:\tlearn: 0.2900691\ttotal: 10.9s\tremaining: 6m 3s\n",
      "29:\tlearn: 0.2871158\ttotal: 11.2s\tremaining: 6m 2s\n",
      "30:\tlearn: 0.2846942\ttotal: 11.6s\tremaining: 6m 2s\n",
      "31:\tlearn: 0.2828571\ttotal: 11.9s\tremaining: 6m 1s\n",
      "32:\tlearn: 0.2804739\ttotal: 12.3s\tremaining: 6m\n",
      "33:\tlearn: 0.2784728\ttotal: 12.7s\tremaining: 5m 59s\n",
      "34:\tlearn: 0.2756821\ttotal: 13s\tremaining: 5m 58s\n",
      "35:\tlearn: 0.2744681\ttotal: 13.4s\tremaining: 5m 58s\n",
      "36:\tlearn: 0.2721063\ttotal: 13.7s\tremaining: 5m 57s\n",
      "37:\tlearn: 0.2698669\ttotal: 14.1s\tremaining: 5m 57s\n",
      "38:\tlearn: 0.2684341\ttotal: 14.5s\tremaining: 5m 56s\n",
      "39:\tlearn: 0.2670465\ttotal: 14.8s\tremaining: 5m 56s\n",
      "40:\tlearn: 0.2657919\ttotal: 15.2s\tremaining: 5m 55s\n",
      "41:\tlearn: 0.2636747\ttotal: 15.6s\tremaining: 5m 54s\n",
      "42:\tlearn: 0.2610653\ttotal: 15.9s\tremaining: 5m 54s\n",
      "43:\tlearn: 0.2591407\ttotal: 16.3s\tremaining: 5m 54s\n",
      "44:\tlearn: 0.2572374\ttotal: 16.7s\tremaining: 5m 53s\n",
      "45:\tlearn: 0.2557956\ttotal: 17s\tremaining: 5m 53s\n",
      "46:\tlearn: 0.2544122\ttotal: 17.4s\tremaining: 5m 52s\n",
      "47:\tlearn: 0.2528580\ttotal: 17.7s\tremaining: 5m 51s\n",
      "48:\tlearn: 0.2517016\ttotal: 18.1s\tremaining: 5m 51s\n",
      "49:\tlearn: 0.2507965\ttotal: 18.5s\tremaining: 5m 51s\n",
      "50:\tlearn: 0.2493449\ttotal: 18.8s\tremaining: 5m 50s\n",
      "51:\tlearn: 0.2479708\ttotal: 19.2s\tremaining: 5m 50s\n",
      "52:\tlearn: 0.2469268\ttotal: 19.6s\tremaining: 5m 49s\n",
      "53:\tlearn: 0.2458028\ttotal: 19.9s\tremaining: 5m 48s\n",
      "54:\tlearn: 0.2440707\ttotal: 20.3s\tremaining: 5m 48s\n",
      "55:\tlearn: 0.2428946\ttotal: 20.6s\tremaining: 5m 47s\n",
      "56:\tlearn: 0.2416881\ttotal: 21s\tremaining: 5m 47s\n",
      "57:\tlearn: 0.2398147\ttotal: 21.4s\tremaining: 5m 46s\n",
      "58:\tlearn: 0.2384406\ttotal: 21.7s\tremaining: 5m 46s\n",
      "59:\tlearn: 0.2368597\ttotal: 22.1s\tremaining: 5m 45s\n",
      "60:\tlearn: 0.2357962\ttotal: 22.5s\tremaining: 5m 45s\n",
      "61:\tlearn: 0.2348962\ttotal: 22.8s\tremaining: 5m 45s\n",
      "62:\tlearn: 0.2338317\ttotal: 23.2s\tremaining: 5m 44s\n",
      "63:\tlearn: 0.2322202\ttotal: 23.6s\tremaining: 5m 44s\n",
      "64:\tlearn: 0.2308317\ttotal: 23.9s\tremaining: 5m 43s\n",
      "65:\tlearn: 0.2296682\ttotal: 24.3s\tremaining: 5m 43s\n",
      "66:\tlearn: 0.2287555\ttotal: 24.6s\tremaining: 5m 43s\n",
      "67:\tlearn: 0.2276592\ttotal: 25s\tremaining: 5m 42s\n",
      "68:\tlearn: 0.2267787\ttotal: 25.4s\tremaining: 5m 42s\n",
      "69:\tlearn: 0.2257550\ttotal: 25.7s\tremaining: 5m 42s\n",
      "70:\tlearn: 0.2239495\ttotal: 26.1s\tremaining: 5m 41s\n",
      "71:\tlearn: 0.2227219\ttotal: 26.5s\tremaining: 5m 41s\n",
      "72:\tlearn: 0.2219648\ttotal: 26.8s\tremaining: 5m 40s\n",
      "73:\tlearn: 0.2213905\ttotal: 27.2s\tremaining: 5m 40s\n",
      "74:\tlearn: 0.2202077\ttotal: 27.6s\tremaining: 5m 40s\n",
      "75:\tlearn: 0.2193541\ttotal: 28s\tremaining: 5m 40s\n",
      "76:\tlearn: 0.2186844\ttotal: 28.3s\tremaining: 5m 39s\n",
      "77:\tlearn: 0.2178481\ttotal: 28.7s\tremaining: 5m 39s\n",
      "78:\tlearn: 0.2168875\ttotal: 29.1s\tremaining: 5m 38s\n",
      "79:\tlearn: 0.2162506\ttotal: 29.4s\tremaining: 5m 38s\n",
      "80:\tlearn: 0.2151520\ttotal: 29.8s\tremaining: 5m 38s\n",
      "81:\tlearn: 0.2146143\ttotal: 30.2s\tremaining: 5m 37s\n",
      "82:\tlearn: 0.2136477\ttotal: 30.5s\tremaining: 5m 37s\n",
      "83:\tlearn: 0.2128397\ttotal: 30.9s\tremaining: 5m 36s\n",
      "84:\tlearn: 0.2122619\ttotal: 31.2s\tremaining: 5m 36s\n",
      "85:\tlearn: 0.2115964\ttotal: 31.6s\tremaining: 5m 35s\n",
      "86:\tlearn: 0.2105213\ttotal: 32s\tremaining: 5m 35s\n",
      "87:\tlearn: 0.2097597\ttotal: 32.3s\tremaining: 5m 34s\n",
      "88:\tlearn: 0.2085386\ttotal: 32.7s\tremaining: 5m 34s\n",
      "89:\tlearn: 0.2075472\ttotal: 33s\tremaining: 5m 34s\n",
      "90:\tlearn: 0.2069004\ttotal: 33.4s\tremaining: 5m 33s\n",
      "91:\tlearn: 0.2063124\ttotal: 33.8s\tremaining: 5m 33s\n",
      "92:\tlearn: 0.2055557\ttotal: 34.1s\tremaining: 5m 32s\n",
      "93:\tlearn: 0.2049305\ttotal: 34.5s\tremaining: 5m 32s\n",
      "94:\tlearn: 0.2040812\ttotal: 34.9s\tremaining: 5m 32s\n",
      "95:\tlearn: 0.2032145\ttotal: 35.2s\tremaining: 5m 31s\n",
      "96:\tlearn: 0.2023980\ttotal: 35.6s\tremaining: 5m 31s\n",
      "97:\tlearn: 0.2018881\ttotal: 36s\tremaining: 5m 31s\n",
      "98:\tlearn: 0.2012277\ttotal: 36.4s\tremaining: 5m 31s\n",
      "99:\tlearn: 0.2007324\ttotal: 36.8s\tremaining: 5m 30s\n",
      "100:\tlearn: 0.2001889\ttotal: 37.1s\tremaining: 5m 30s\n",
      "101:\tlearn: 0.1997571\ttotal: 37.5s\tremaining: 5m 30s\n",
      "102:\tlearn: 0.1992883\ttotal: 37.9s\tremaining: 5m 29s\n",
      "103:\tlearn: 0.1988239\ttotal: 38.2s\tremaining: 5m 29s\n",
      "104:\tlearn: 0.1982423\ttotal: 38.6s\tremaining: 5m 29s\n",
      "105:\tlearn: 0.1977295\ttotal: 39s\tremaining: 5m 28s\n",
      "106:\tlearn: 0.1967118\ttotal: 39.4s\tremaining: 5m 28s\n",
      "107:\tlearn: 0.1957515\ttotal: 39.7s\tremaining: 5m 28s\n",
      "108:\tlearn: 0.1951433\ttotal: 40.1s\tremaining: 5m 27s\n",
      "109:\tlearn: 0.1946142\ttotal: 40.5s\tremaining: 5m 27s\n",
      "110:\tlearn: 0.1942548\ttotal: 40.8s\tremaining: 5m 27s\n",
      "111:\tlearn: 0.1936382\ttotal: 41.2s\tremaining: 5m 26s\n",
      "112:\tlearn: 0.1931331\ttotal: 41.6s\tremaining: 5m 26s\n",
      "113:\tlearn: 0.1924351\ttotal: 41.9s\tremaining: 5m 26s\n",
      "114:\tlearn: 0.1913633\ttotal: 42.3s\tremaining: 5m 25s\n",
      "115:\tlearn: 0.1905102\ttotal: 42.7s\tremaining: 5m 25s\n",
      "116:\tlearn: 0.1896733\ttotal: 43.1s\tremaining: 5m 24s\n",
      "117:\tlearn: 0.1891507\ttotal: 43.4s\tremaining: 5m 24s\n",
      "118:\tlearn: 0.1885003\ttotal: 43.8s\tremaining: 5m 24s\n",
      "119:\tlearn: 0.1881577\ttotal: 44.2s\tremaining: 5m 23s\n",
      "120:\tlearn: 0.1873180\ttotal: 44.5s\tremaining: 5m 23s\n",
      "121:\tlearn: 0.1867946\ttotal: 44.9s\tremaining: 5m 23s\n",
      "122:\tlearn: 0.1863539\ttotal: 45.3s\tremaining: 5m 22s\n",
      "123:\tlearn: 0.1856249\ttotal: 45.6s\tremaining: 5m 22s\n",
      "124:\tlearn: 0.1852239\ttotal: 46s\tremaining: 5m 21s\n",
      "125:\tlearn: 0.1845769\ttotal: 46.4s\tremaining: 5m 21s\n",
      "126:\tlearn: 0.1840023\ttotal: 46.7s\tremaining: 5m 21s\n",
      "127:\tlearn: 0.1834807\ttotal: 47.1s\tremaining: 5m 21s\n",
      "128:\tlearn: 0.1826647\ttotal: 47.5s\tremaining: 5m 20s\n",
      "129:\tlearn: 0.1815405\ttotal: 47.9s\tremaining: 5m 20s\n",
      "130:\tlearn: 0.1811648\ttotal: 48.2s\tremaining: 5m 19s\n",
      "131:\tlearn: 0.1806127\ttotal: 48.6s\tremaining: 5m 19s\n",
      "132:\tlearn: 0.1802041\ttotal: 49s\tremaining: 5m 19s\n",
      "133:\tlearn: 0.1798102\ttotal: 49.3s\tremaining: 5m 18s\n",
      "134:\tlearn: 0.1794220\ttotal: 49.7s\tremaining: 5m 18s\n",
      "135:\tlearn: 0.1788254\ttotal: 50.1s\tremaining: 5m 18s\n",
      "136:\tlearn: 0.1780756\ttotal: 50.4s\tremaining: 5m 17s\n",
      "137:\tlearn: 0.1776839\ttotal: 50.8s\tremaining: 5m 17s\n",
      "138:\tlearn: 0.1774354\ttotal: 51.2s\tremaining: 5m 16s\n",
      "139:\tlearn: 0.1769118\ttotal: 51.5s\tremaining: 5m 16s\n",
      "140:\tlearn: 0.1764517\ttotal: 51.9s\tremaining: 5m 16s\n",
      "141:\tlearn: 0.1756838\ttotal: 52.2s\tremaining: 5m 15s\n",
      "142:\tlearn: 0.1749740\ttotal: 52.6s\tremaining: 5m 15s\n",
      "143:\tlearn: 0.1746112\ttotal: 53s\tremaining: 5m 14s\n",
      "144:\tlearn: 0.1742381\ttotal: 53.3s\tremaining: 5m 14s\n",
      "145:\tlearn: 0.1737019\ttotal: 53.7s\tremaining: 5m 14s\n",
      "146:\tlearn: 0.1733192\ttotal: 54.1s\tremaining: 5m 13s\n",
      "147:\tlearn: 0.1727713\ttotal: 54.4s\tremaining: 5m 13s\n",
      "148:\tlearn: 0.1723950\ttotal: 54.8s\tremaining: 5m 13s\n",
      "149:\tlearn: 0.1718344\ttotal: 55.2s\tremaining: 5m 12s\n",
      "150:\tlearn: 0.1714289\ttotal: 55.5s\tremaining: 5m 12s\n",
      "151:\tlearn: 0.1707611\ttotal: 55.9s\tremaining: 5m 11s\n",
      "152:\tlearn: 0.1701645\ttotal: 56.3s\tremaining: 5m 11s\n",
      "153:\tlearn: 0.1699178\ttotal: 56.6s\tremaining: 5m 11s\n",
      "154:\tlearn: 0.1694801\ttotal: 57s\tremaining: 5m 10s\n",
      "155:\tlearn: 0.1691933\ttotal: 57.4s\tremaining: 5m 10s\n",
      "156:\tlearn: 0.1680576\ttotal: 57.7s\tremaining: 5m 10s\n",
      "157:\tlearn: 0.1676607\ttotal: 58.1s\tremaining: 5m 9s\n",
      "158:\tlearn: 0.1673505\ttotal: 58.5s\tremaining: 5m 9s\n",
      "159:\tlearn: 0.1668749\ttotal: 58.8s\tremaining: 5m 8s\n",
      "160:\tlearn: 0.1663040\ttotal: 59.2s\tremaining: 5m 8s\n",
      "161:\tlearn: 0.1657805\ttotal: 59.6s\tremaining: 5m 8s\n",
      "162:\tlearn: 0.1652811\ttotal: 59.9s\tremaining: 5m 7s\n",
      "163:\tlearn: 0.1650620\ttotal: 1m\tremaining: 5m 7s\n",
      "164:\tlearn: 0.1646509\ttotal: 1m\tremaining: 5m 7s\n",
      "165:\tlearn: 0.1638363\ttotal: 1m 1s\tremaining: 5m 6s\n",
      "166:\tlearn: 0.1635642\ttotal: 1m 1s\tremaining: 5m 6s\n",
      "167:\tlearn: 0.1632669\ttotal: 1m 1s\tremaining: 5m 5s\n",
      "168:\tlearn: 0.1628685\ttotal: 1m 2s\tremaining: 5m 5s\n",
      "169:\tlearn: 0.1623801\ttotal: 1m 2s\tremaining: 5m 5s\n",
      "170:\tlearn: 0.1620505\ttotal: 1m 2s\tremaining: 5m 4s\n",
      "171:\tlearn: 0.1617105\ttotal: 1m 3s\tremaining: 5m 4s\n",
      "172:\tlearn: 0.1615043\ttotal: 1m 3s\tremaining: 5m 3s\n",
      "173:\tlearn: 0.1612234\ttotal: 1m 3s\tremaining: 5m 3s\n",
      "174:\tlearn: 0.1608495\ttotal: 1m 4s\tremaining: 5m 3s\n",
      "175:\tlearn: 0.1601978\ttotal: 1m 4s\tremaining: 5m 2s\n",
      "176:\tlearn: 0.1599821\ttotal: 1m 5s\tremaining: 5m 2s\n",
      "177:\tlearn: 0.1597049\ttotal: 1m 5s\tremaining: 5m 1s\n",
      "178:\tlearn: 0.1595328\ttotal: 1m 5s\tremaining: 5m 1s\n",
      "179:\tlearn: 0.1587286\ttotal: 1m 6s\tremaining: 5m 1s\n",
      "180:\tlearn: 0.1584217\ttotal: 1m 6s\tremaining: 5m\n",
      "181:\tlearn: 0.1580438\ttotal: 1m 6s\tremaining: 5m\n",
      "182:\tlearn: 0.1577490\ttotal: 1m 7s\tremaining: 4m 59s\n",
      "183:\tlearn: 0.1574541\ttotal: 1m 7s\tremaining: 4m 59s\n",
      "184:\tlearn: 0.1569157\ttotal: 1m 7s\tremaining: 4m 59s\n",
      "185:\tlearn: 0.1562846\ttotal: 1m 8s\tremaining: 4m 58s\n",
      "186:\tlearn: 0.1560186\ttotal: 1m 8s\tremaining: 4m 58s\n",
      "187:\tlearn: 0.1556241\ttotal: 1m 8s\tremaining: 4m 57s\n",
      "188:\tlearn: 0.1550736\ttotal: 1m 9s\tremaining: 4m 57s\n",
      "189:\tlearn: 0.1548443\ttotal: 1m 9s\tremaining: 4m 57s\n",
      "190:\tlearn: 0.1544952\ttotal: 1m 10s\tremaining: 4m 56s\n",
      "191:\tlearn: 0.1541945\ttotal: 1m 10s\tremaining: 4m 56s\n",
      "192:\tlearn: 0.1540183\ttotal: 1m 10s\tremaining: 4m 55s\n",
      "193:\tlearn: 0.1538555\ttotal: 1m 11s\tremaining: 4m 55s\n",
      "194:\tlearn: 0.1535887\ttotal: 1m 11s\tremaining: 4m 54s\n",
      "195:\tlearn: 0.1530486\ttotal: 1m 11s\tremaining: 4m 54s\n",
      "196:\tlearn: 0.1526918\ttotal: 1m 12s\tremaining: 4m 54s\n",
      "197:\tlearn: 0.1524066\ttotal: 1m 12s\tremaining: 4m 53s\n",
      "198:\tlearn: 0.1518549\ttotal: 1m 12s\tremaining: 4m 53s\n",
      "199:\tlearn: 0.1516189\ttotal: 1m 13s\tremaining: 4m 52s\n",
      "200:\tlearn: 0.1510365\ttotal: 1m 13s\tremaining: 4m 52s\n",
      "201:\tlearn: 0.1508647\ttotal: 1m 13s\tremaining: 4m 52s\n",
      "202:\tlearn: 0.1505977\ttotal: 1m 14s\tremaining: 4m 51s\n",
      "203:\tlearn: 0.1503991\ttotal: 1m 14s\tremaining: 4m 51s\n",
      "204:\tlearn: 0.1501662\ttotal: 1m 15s\tremaining: 4m 50s\n",
      "205:\tlearn: 0.1498294\ttotal: 1m 15s\tremaining: 4m 50s\n",
      "206:\tlearn: 0.1495531\ttotal: 1m 15s\tremaining: 4m 50s\n",
      "207:\tlearn: 0.1490439\ttotal: 1m 16s\tremaining: 4m 49s\n",
      "208:\tlearn: 0.1486402\ttotal: 1m 16s\tremaining: 4m 49s\n",
      "209:\tlearn: 0.1485286\ttotal: 1m 16s\tremaining: 4m 49s\n",
      "210:\tlearn: 0.1480979\ttotal: 1m 17s\tremaining: 4m 48s\n",
      "211:\tlearn: 0.1478695\ttotal: 1m 17s\tremaining: 4m 48s\n",
      "212:\tlearn: 0.1477083\ttotal: 1m 17s\tremaining: 4m 48s\n",
      "213:\tlearn: 0.1474096\ttotal: 1m 18s\tremaining: 4m 47s\n",
      "214:\tlearn: 0.1472032\ttotal: 1m 18s\tremaining: 4m 47s\n",
      "215:\tlearn: 0.1467186\ttotal: 1m 19s\tremaining: 4m 47s\n",
      "216:\tlearn: 0.1463598\ttotal: 1m 19s\tremaining: 4m 47s\n",
      "217:\tlearn: 0.1461373\ttotal: 1m 19s\tremaining: 4m 46s\n",
      "218:\tlearn: 0.1456854\ttotal: 1m 20s\tremaining: 4m 46s\n",
      "219:\tlearn: 0.1454016\ttotal: 1m 20s\tremaining: 4m 46s\n",
      "220:\tlearn: 0.1452881\ttotal: 1m 21s\tremaining: 4m 45s\n",
      "221:\tlearn: 0.1449187\ttotal: 1m 21s\tremaining: 4m 45s\n",
      "222:\tlearn: 0.1447119\ttotal: 1m 21s\tremaining: 4m 44s\n",
      "223:\tlearn: 0.1442735\ttotal: 1m 22s\tremaining: 4m 44s\n",
      "224:\tlearn: 0.1435326\ttotal: 1m 22s\tremaining: 4m 44s\n",
      "225:\tlearn: 0.1434192\ttotal: 1m 22s\tremaining: 4m 44s\n",
      "226:\tlearn: 0.1431688\ttotal: 1m 23s\tremaining: 4m 43s\n",
      "227:\tlearn: 0.1429529\ttotal: 1m 23s\tremaining: 4m 43s\n",
      "228:\tlearn: 0.1427620\ttotal: 1m 24s\tremaining: 4m 43s\n",
      "229:\tlearn: 0.1423877\ttotal: 1m 24s\tremaining: 4m 42s\n",
      "230:\tlearn: 0.1421545\ttotal: 1m 24s\tremaining: 4m 42s\n",
      "231:\tlearn: 0.1419985\ttotal: 1m 25s\tremaining: 4m 41s\n",
      "232:\tlearn: 0.1415470\ttotal: 1m 25s\tremaining: 4m 41s\n",
      "233:\tlearn: 0.1413582\ttotal: 1m 25s\tremaining: 4m 41s\n",
      "234:\tlearn: 0.1412496\ttotal: 1m 26s\tremaining: 4m 40s\n",
      "235:\tlearn: 0.1409676\ttotal: 1m 26s\tremaining: 4m 40s\n",
      "236:\tlearn: 0.1408450\ttotal: 1m 27s\tremaining: 4m 40s\n",
      "237:\tlearn: 0.1406189\ttotal: 1m 27s\tremaining: 4m 39s\n",
      "238:\tlearn: 0.1404166\ttotal: 1m 27s\tremaining: 4m 39s\n",
      "239:\tlearn: 0.1401278\ttotal: 1m 28s\tremaining: 4m 39s\n",
      "240:\tlearn: 0.1395356\ttotal: 1m 28s\tremaining: 4m 38s\n",
      "241:\tlearn: 0.1394296\ttotal: 1m 28s\tremaining: 4m 38s\n",
      "242:\tlearn: 0.1392545\ttotal: 1m 29s\tremaining: 4m 38s\n",
      "243:\tlearn: 0.1391555\ttotal: 1m 29s\tremaining: 4m 37s\n",
      "244:\tlearn: 0.1387253\ttotal: 1m 29s\tremaining: 4m 37s\n",
      "245:\tlearn: 0.1384232\ttotal: 1m 30s\tremaining: 4m 36s\n",
      "246:\tlearn: 0.1382254\ttotal: 1m 30s\tremaining: 4m 36s\n",
      "247:\tlearn: 0.1380224\ttotal: 1m 31s\tremaining: 4m 36s\n",
      "248:\tlearn: 0.1376380\ttotal: 1m 31s\tremaining: 4m 35s\n",
      "249:\tlearn: 0.1371902\ttotal: 1m 31s\tremaining: 4m 35s\n",
      "250:\tlearn: 0.1370924\ttotal: 1m 32s\tremaining: 4m 35s\n",
      "251:\tlearn: 0.1369069\ttotal: 1m 32s\tremaining: 4m 34s\n",
      "252:\tlearn: 0.1367277\ttotal: 1m 32s\tremaining: 4m 34s\n",
      "253:\tlearn: 0.1363137\ttotal: 1m 33s\tremaining: 4m 34s\n",
      "254:\tlearn: 0.1361851\ttotal: 1m 33s\tremaining: 4m 33s\n",
      "255:\tlearn: 0.1360903\ttotal: 1m 34s\tremaining: 4m 33s\n",
      "256:\tlearn: 0.1358738\ttotal: 1m 34s\tremaining: 4m 33s\n",
      "257:\tlearn: 0.1357546\ttotal: 1m 35s\tremaining: 4m 34s\n",
      "258:\tlearn: 0.1356209\ttotal: 1m 35s\tremaining: 4m 34s\n",
      "259:\tlearn: 0.1352770\ttotal: 1m 36s\tremaining: 4m 34s\n",
      "260:\tlearn: 0.1347932\ttotal: 1m 36s\tremaining: 4m 33s\n",
      "261:\tlearn: 0.1345707\ttotal: 1m 37s\tremaining: 4m 33s\n",
      "262:\tlearn: 0.1344146\ttotal: 1m 37s\tremaining: 4m 33s\n",
      "263:\tlearn: 0.1343261\ttotal: 1m 37s\tremaining: 4m 32s\n",
      "264:\tlearn: 0.1341256\ttotal: 1m 38s\tremaining: 4m 32s\n",
      "265:\tlearn: 0.1340246\ttotal: 1m 38s\tremaining: 4m 32s\n",
      "266:\tlearn: 0.1339278\ttotal: 1m 38s\tremaining: 4m 31s\n",
      "267:\tlearn: 0.1336847\ttotal: 1m 39s\tremaining: 4m 31s\n",
      "268:\tlearn: 0.1335507\ttotal: 1m 39s\tremaining: 4m 30s\n",
      "269:\tlearn: 0.1332977\ttotal: 1m 40s\tremaining: 4m 30s\n",
      "270:\tlearn: 0.1331613\ttotal: 1m 40s\tremaining: 4m 30s\n",
      "271:\tlearn: 0.1330715\ttotal: 1m 40s\tremaining: 4m 29s\n",
      "272:\tlearn: 0.1329013\ttotal: 1m 41s\tremaining: 4m 29s\n",
      "273:\tlearn: 0.1327812\ttotal: 1m 41s\tremaining: 4m 28s\n",
      "274:\tlearn: 0.1325770\ttotal: 1m 41s\tremaining: 4m 28s\n",
      "275:\tlearn: 0.1323669\ttotal: 1m 42s\tremaining: 4m 28s\n",
      "276:\tlearn: 0.1321078\ttotal: 1m 42s\tremaining: 4m 27s\n",
      "277:\tlearn: 0.1318476\ttotal: 1m 42s\tremaining: 4m 27s\n",
      "278:\tlearn: 0.1317078\ttotal: 1m 43s\tremaining: 4m 27s\n",
      "279:\tlearn: 0.1316155\ttotal: 1m 43s\tremaining: 4m 26s\n",
      "280:\tlearn: 0.1315353\ttotal: 1m 44s\tremaining: 4m 26s\n",
      "281:\tlearn: 0.1311912\ttotal: 1m 44s\tremaining: 4m 25s\n",
      "282:\tlearn: 0.1310554\ttotal: 1m 44s\tremaining: 4m 25s\n",
      "283:\tlearn: 0.1309447\ttotal: 1m 45s\tremaining: 4m 25s\n",
      "284:\tlearn: 0.1306563\ttotal: 1m 45s\tremaining: 4m 24s\n",
      "285:\tlearn: 0.1305766\ttotal: 1m 45s\tremaining: 4m 24s\n",
      "286:\tlearn: 0.1303987\ttotal: 1m 46s\tremaining: 4m 23s\n",
      "287:\tlearn: 0.1296762\ttotal: 1m 46s\tremaining: 4m 23s\n",
      "288:\tlearn: 0.1295207\ttotal: 1m 46s\tremaining: 4m 23s\n",
      "289:\tlearn: 0.1293129\ttotal: 1m 47s\tremaining: 4m 22s\n",
      "290:\tlearn: 0.1291468\ttotal: 1m 47s\tremaining: 4m 22s\n",
      "291:\tlearn: 0.1290646\ttotal: 1m 48s\tremaining: 4m 21s\n",
      "292:\tlearn: 0.1289582\ttotal: 1m 48s\tremaining: 4m 21s\n",
      "293:\tlearn: 0.1287976\ttotal: 1m 48s\tremaining: 4m 21s\n",
      "294:\tlearn: 0.1282671\ttotal: 1m 49s\tremaining: 4m 20s\n",
      "295:\tlearn: 0.1280285\ttotal: 1m 49s\tremaining: 4m 20s\n",
      "296:\tlearn: 0.1279406\ttotal: 1m 49s\tremaining: 4m 20s\n",
      "297:\tlearn: 0.1277635\ttotal: 1m 50s\tremaining: 4m 19s\n",
      "298:\tlearn: 0.1275659\ttotal: 1m 50s\tremaining: 4m 19s\n",
      "299:\tlearn: 0.1274811\ttotal: 1m 50s\tremaining: 4m 18s\n",
      "300:\tlearn: 0.1272574\ttotal: 1m 51s\tremaining: 4m 18s\n",
      "301:\tlearn: 0.1271728\ttotal: 1m 51s\tremaining: 4m 18s\n",
      "302:\tlearn: 0.1269106\ttotal: 1m 52s\tremaining: 4m 17s\n",
      "303:\tlearn: 0.1267757\ttotal: 1m 52s\tremaining: 4m 17s\n",
      "304:\tlearn: 0.1265962\ttotal: 1m 52s\tremaining: 4m 16s\n",
      "305:\tlearn: 0.1264586\ttotal: 1m 53s\tremaining: 4m 16s\n",
      "306:\tlearn: 0.1263701\ttotal: 1m 53s\tremaining: 4m 16s\n",
      "307:\tlearn: 0.1262051\ttotal: 1m 53s\tremaining: 4m 15s\n",
      "308:\tlearn: 0.1259633\ttotal: 1m 54s\tremaining: 4m 15s\n",
      "309:\tlearn: 0.1257068\ttotal: 1m 54s\tremaining: 4m 14s\n",
      "310:\tlearn: 0.1255294\ttotal: 1m 54s\tremaining: 4m 14s\n",
      "311:\tlearn: 0.1250506\ttotal: 1m 55s\tremaining: 4m 14s\n",
      "312:\tlearn: 0.1248252\ttotal: 1m 55s\tremaining: 4m 13s\n",
      "313:\tlearn: 0.1247022\ttotal: 1m 56s\tremaining: 4m 13s\n",
      "314:\tlearn: 0.1246283\ttotal: 1m 56s\tremaining: 4m 13s\n",
      "315:\tlearn: 0.1245523\ttotal: 1m 56s\tremaining: 4m 12s\n",
      "316:\tlearn: 0.1244672\ttotal: 1m 57s\tremaining: 4m 12s\n",
      "317:\tlearn: 0.1240592\ttotal: 1m 57s\tremaining: 4m 11s\n",
      "318:\tlearn: 0.1239758\ttotal: 1m 57s\tremaining: 4m 11s\n",
      "319:\tlearn: 0.1236098\ttotal: 1m 58s\tremaining: 4m 11s\n",
      "320:\tlearn: 0.1234964\ttotal: 1m 58s\tremaining: 4m 10s\n",
      "321:\tlearn: 0.1233238\ttotal: 1m 58s\tremaining: 4m 10s\n",
      "322:\tlearn: 0.1230342\ttotal: 1m 59s\tremaining: 4m 10s\n",
      "323:\tlearn: 0.1229572\ttotal: 1m 59s\tremaining: 4m 9s\n",
      "324:\tlearn: 0.1226949\ttotal: 2m\tremaining: 4m 9s\n",
      "325:\tlearn: 0.1224430\ttotal: 2m\tremaining: 4m 8s\n",
      "326:\tlearn: 0.1223723\ttotal: 2m\tremaining: 4m 8s\n",
      "327:\tlearn: 0.1222080\ttotal: 2m 1s\tremaining: 4m 8s\n",
      "328:\tlearn: 0.1221295\ttotal: 2m 1s\tremaining: 4m 7s\n",
      "329:\tlearn: 0.1219437\ttotal: 2m 1s\tremaining: 4m 7s\n",
      "330:\tlearn: 0.1217176\ttotal: 2m 2s\tremaining: 4m 6s\n",
      "331:\tlearn: 0.1215747\ttotal: 2m 2s\tremaining: 4m 6s\n",
      "332:\tlearn: 0.1215072\ttotal: 2m 2s\tremaining: 4m 6s\n",
      "333:\tlearn: 0.1213093\ttotal: 2m 3s\tremaining: 4m 5s\n",
      "334:\tlearn: 0.1212327\ttotal: 2m 3s\tremaining: 4m 5s\n",
      "335:\tlearn: 0.1210559\ttotal: 2m 3s\tremaining: 4m 4s\n",
      "336:\tlearn: 0.1208595\ttotal: 2m 4s\tremaining: 4m 4s\n",
      "337:\tlearn: 0.1207967\ttotal: 2m 4s\tremaining: 4m 4s\n",
      "338:\tlearn: 0.1206348\ttotal: 2m 4s\tremaining: 4m 3s\n",
      "339:\tlearn: 0.1203070\ttotal: 2m 5s\tremaining: 4m 3s\n",
      "340:\tlearn: 0.1199792\ttotal: 2m 5s\tremaining: 4m 2s\n",
      "341:\tlearn: 0.1198041\ttotal: 2m 6s\tremaining: 4m 2s\n",
      "342:\tlearn: 0.1197327\ttotal: 2m 6s\tremaining: 4m 2s\n",
      "343:\tlearn: 0.1194322\ttotal: 2m 6s\tremaining: 4m 1s\n",
      "344:\tlearn: 0.1193431\ttotal: 2m 7s\tremaining: 4m 1s\n",
      "345:\tlearn: 0.1192660\ttotal: 2m 7s\tremaining: 4m\n",
      "346:\tlearn: 0.1191921\ttotal: 2m 7s\tremaining: 4m\n",
      "347:\tlearn: 0.1191315\ttotal: 2m 8s\tremaining: 4m\n",
      "348:\tlearn: 0.1189753\ttotal: 2m 8s\tremaining: 3m 59s\n",
      "349:\tlearn: 0.1186042\ttotal: 2m 8s\tremaining: 3m 59s\n",
      "350:\tlearn: 0.1184953\ttotal: 2m 9s\tremaining: 3m 58s\n",
      "351:\tlearn: 0.1183833\ttotal: 2m 9s\tremaining: 3m 58s\n",
      "352:\tlearn: 0.1181649\ttotal: 2m 9s\tremaining: 3m 58s\n",
      "353:\tlearn: 0.1180195\ttotal: 2m 10s\tremaining: 3m 57s\n",
      "354:\tlearn: 0.1179612\ttotal: 2m 10s\tremaining: 3m 57s\n",
      "355:\tlearn: 0.1177275\ttotal: 2m 10s\tremaining: 3m 56s\n",
      "356:\tlearn: 0.1176588\ttotal: 2m 11s\tremaining: 3m 56s\n",
      "357:\tlearn: 0.1175938\ttotal: 2m 11s\tremaining: 3m 56s\n",
      "358:\tlearn: 0.1174499\ttotal: 2m 12s\tremaining: 3m 55s\n",
      "359:\tlearn: 0.1173460\ttotal: 2m 12s\tremaining: 3m 55s\n",
      "360:\tlearn: 0.1171422\ttotal: 2m 12s\tremaining: 3m 55s\n",
      "361:\tlearn: 0.1170617\ttotal: 2m 13s\tremaining: 3m 54s\n",
      "362:\tlearn: 0.1169227\ttotal: 2m 13s\tremaining: 3m 54s\n",
      "363:\tlearn: 0.1166725\ttotal: 2m 13s\tremaining: 3m 54s\n",
      "364:\tlearn: 0.1165992\ttotal: 2m 14s\tremaining: 3m 53s\n",
      "365:\tlearn: 0.1164559\ttotal: 2m 14s\tremaining: 3m 53s\n",
      "366:\tlearn: 0.1163990\ttotal: 2m 15s\tremaining: 3m 52s\n",
      "367:\tlearn: 0.1161450\ttotal: 2m 15s\tremaining: 3m 52s\n",
      "368:\tlearn: 0.1159633\ttotal: 2m 15s\tremaining: 3m 52s\n",
      "369:\tlearn: 0.1159085\ttotal: 2m 16s\tremaining: 3m 51s\n",
      "370:\tlearn: 0.1157978\ttotal: 2m 16s\tremaining: 3m 51s\n",
      "371:\tlearn: 0.1156095\ttotal: 2m 16s\tremaining: 3m 51s\n",
      "372:\tlearn: 0.1155572\ttotal: 2m 17s\tremaining: 3m 50s\n",
      "373:\tlearn: 0.1155056\ttotal: 2m 17s\tremaining: 3m 50s\n",
      "374:\tlearn: 0.1153150\ttotal: 2m 18s\tremaining: 3m 50s\n",
      "375:\tlearn: 0.1152631\ttotal: 2m 18s\tremaining: 3m 49s\n",
      "376:\tlearn: 0.1151266\ttotal: 2m 18s\tremaining: 3m 49s\n",
      "377:\tlearn: 0.1149625\ttotal: 2m 19s\tremaining: 3m 49s\n",
      "378:\tlearn: 0.1146721\ttotal: 2m 19s\tremaining: 3m 48s\n",
      "379:\tlearn: 0.1146169\ttotal: 2m 19s\tremaining: 3m 48s\n",
      "380:\tlearn: 0.1144498\ttotal: 2m 20s\tremaining: 3m 48s\n",
      "381:\tlearn: 0.1143878\ttotal: 2m 20s\tremaining: 3m 47s\n",
      "382:\tlearn: 0.1142442\ttotal: 2m 21s\tremaining: 3m 47s\n",
      "383:\tlearn: 0.1140787\ttotal: 2m 21s\tremaining: 3m 46s\n",
      "384:\tlearn: 0.1139664\ttotal: 2m 21s\tremaining: 3m 46s\n",
      "385:\tlearn: 0.1138839\ttotal: 2m 22s\tremaining: 3m 46s\n",
      "386:\tlearn: 0.1138310\ttotal: 2m 22s\tremaining: 3m 45s\n",
      "387:\tlearn: 0.1137791\ttotal: 2m 23s\tremaining: 3m 45s\n",
      "388:\tlearn: 0.1137271\ttotal: 2m 23s\tremaining: 3m 45s\n",
      "389:\tlearn: 0.1136728\ttotal: 2m 23s\tremaining: 3m 44s\n",
      "390:\tlearn: 0.1136201\ttotal: 2m 24s\tremaining: 3m 44s\n",
      "391:\tlearn: 0.1135677\ttotal: 2m 24s\tremaining: 3m 44s\n",
      "392:\tlearn: 0.1135148\ttotal: 2m 25s\tremaining: 3m 44s\n",
      "393:\tlearn: 0.1134633\ttotal: 2m 25s\tremaining: 3m 44s\n",
      "394:\tlearn: 0.1134105\ttotal: 2m 26s\tremaining: 3m 44s\n",
      "395:\tlearn: 0.1133302\ttotal: 2m 27s\tremaining: 3m 44s\n",
      "396:\tlearn: 0.1132107\ttotal: 2m 28s\tremaining: 3m 44s\n",
      "397:\tlearn: 0.1129845\ttotal: 2m 28s\tremaining: 3m 45s\n",
      "398:\tlearn: 0.1127922\ttotal: 2m 29s\tremaining: 3m 45s\n",
      "399:\tlearn: 0.1127404\ttotal: 2m 30s\tremaining: 3m 45s\n",
      "400:\tlearn: 0.1124989\ttotal: 2m 30s\tremaining: 3m 45s\n",
      "401:\tlearn: 0.1123507\ttotal: 2m 31s\tremaining: 3m 45s\n",
      "402:\tlearn: 0.1122982\ttotal: 2m 32s\tremaining: 3m 45s\n",
      "403:\tlearn: 0.1122445\ttotal: 2m 33s\tremaining: 3m 45s\n",
      "404:\tlearn: 0.1121906\ttotal: 2m 33s\tremaining: 3m 46s\n",
      "405:\tlearn: 0.1121364\ttotal: 2m 34s\tremaining: 3m 46s\n",
      "406:\tlearn: 0.1120554\ttotal: 2m 35s\tremaining: 3m 46s\n",
      "407:\tlearn: 0.1120004\ttotal: 2m 36s\tremaining: 3m 46s\n",
      "408:\tlearn: 0.1119021\ttotal: 2m 36s\tremaining: 3m 46s\n",
      "409:\tlearn: 0.1118355\ttotal: 2m 37s\tremaining: 3m 46s\n",
      "410:\tlearn: 0.1117824\ttotal: 2m 38s\tremaining: 3m 46s\n",
      "411:\tlearn: 0.1117303\ttotal: 2m 38s\tremaining: 3m 46s\n",
      "412:\tlearn: 0.1116769\ttotal: 2m 39s\tremaining: 3m 46s\n",
      "413:\tlearn: 0.1116241\ttotal: 2m 40s\tremaining: 3m 46s\n",
      "414:\tlearn: 0.1115748\ttotal: 2m 41s\tremaining: 3m 46s\n",
      "415:\tlearn: 0.1115242\ttotal: 2m 41s\tremaining: 3m 47s\n",
      "416:\tlearn: 0.1114307\ttotal: 2m 42s\tremaining: 3m 47s\n",
      "417:\tlearn: 0.1113823\ttotal: 2m 43s\tremaining: 3m 47s\n",
      "418:\tlearn: 0.1111651\ttotal: 2m 43s\tremaining: 3m 47s\n",
      "419:\tlearn: 0.1110482\ttotal: 2m 44s\tremaining: 3m 47s\n",
      "420:\tlearn: 0.1109927\ttotal: 2m 45s\tremaining: 3m 47s\n",
      "421:\tlearn: 0.1109434\ttotal: 2m 46s\tremaining: 3m 47s\n",
      "422:\tlearn: 0.1108279\ttotal: 2m 46s\tremaining: 3m 47s\n",
      "423:\tlearn: 0.1107805\ttotal: 2m 47s\tremaining: 3m 47s\n",
      "424:\tlearn: 0.1107115\ttotal: 2m 48s\tremaining: 3m 47s\n",
      "425:\tlearn: 0.1106487\ttotal: 2m 49s\tremaining: 3m 47s\n",
      "426:\tlearn: 0.1105276\ttotal: 2m 49s\tremaining: 3m 47s\n",
      "427:\tlearn: 0.1104607\ttotal: 2m 50s\tremaining: 3m 47s\n",
      "428:\tlearn: 0.1104123\ttotal: 2m 51s\tremaining: 3m 47s\n",
      "429:\tlearn: 0.1102952\ttotal: 2m 51s\tremaining: 3m 47s\n",
      "430:\tlearn: 0.1102217\ttotal: 2m 52s\tremaining: 3m 47s\n",
      "431:\tlearn: 0.1100364\ttotal: 2m 53s\tremaining: 3m 47s\n",
      "432:\tlearn: 0.1099006\ttotal: 2m 54s\tremaining: 3m 47s\n",
      "433:\tlearn: 0.1098552\ttotal: 2m 54s\tremaining: 3m 47s\n",
      "434:\tlearn: 0.1096579\ttotal: 2m 55s\tremaining: 3m 47s\n",
      "435:\tlearn: 0.1096027\ttotal: 2m 56s\tremaining: 3m 47s\n",
      "436:\tlearn: 0.1095566\ttotal: 2m 56s\tremaining: 3m 47s\n",
      "437:\tlearn: 0.1094334\ttotal: 2m 57s\tremaining: 3m 47s\n",
      "438:\tlearn: 0.1092346\ttotal: 2m 58s\tremaining: 3m 48s\n",
      "439:\tlearn: 0.1091877\ttotal: 2m 59s\tremaining: 3m 48s\n",
      "440:\tlearn: 0.1091399\ttotal: 2m 59s\tremaining: 3m 48s\n",
      "441:\tlearn: 0.1090926\ttotal: 3m\tremaining: 3m 47s\n",
      "442:\tlearn: 0.1090464\ttotal: 3m 1s\tremaining: 3m 47s\n",
      "443:\tlearn: 0.1089999\ttotal: 3m 2s\tremaining: 3m 47s\n",
      "444:\tlearn: 0.1088744\ttotal: 3m 2s\tremaining: 3m 47s\n",
      "445:\tlearn: 0.1088219\ttotal: 3m 3s\tremaining: 3m 47s\n",
      "446:\tlearn: 0.1087754\ttotal: 3m 4s\tremaining: 3m 47s\n",
      "447:\tlearn: 0.1087289\ttotal: 3m 4s\tremaining: 3m 47s\n",
      "448:\tlearn: 0.1086349\ttotal: 3m 5s\tremaining: 3m 47s\n",
      "449:\tlearn: 0.1085873\ttotal: 3m 6s\tremaining: 3m 47s\n",
      "450:\tlearn: 0.1082757\ttotal: 3m 7s\tremaining: 3m 47s\n",
      "451:\tlearn: 0.1082289\ttotal: 3m 8s\tremaining: 3m 47s\n",
      "452:\tlearn: 0.1081819\ttotal: 3m 8s\tremaining: 3m 48s\n",
      "453:\tlearn: 0.1076689\ttotal: 3m 9s\tremaining: 3m 48s\n",
      "454:\tlearn: 0.1076193\ttotal: 3m 10s\tremaining: 3m 48s\n",
      "455:\tlearn: 0.1075023\ttotal: 3m 11s\tremaining: 3m 47s\n",
      "456:\tlearn: 0.1074514\ttotal: 3m 11s\tremaining: 3m 47s\n",
      "457:\tlearn: 0.1074048\ttotal: 3m 11s\tremaining: 3m 46s\n",
      "458:\tlearn: 0.1073577\ttotal: 3m 12s\tremaining: 3m 46s\n",
      "459:\tlearn: 0.1073098\ttotal: 3m 12s\tremaining: 3m 46s\n",
      "460:\tlearn: 0.1072614\ttotal: 3m 12s\tremaining: 3m 45s\n",
      "461:\tlearn: 0.1072147\ttotal: 3m 13s\tremaining: 3m 45s\n",
      "462:\tlearn: 0.1071688\ttotal: 3m 13s\tremaining: 3m 44s\n",
      "463:\tlearn: 0.1070895\ttotal: 3m 14s\tremaining: 3m 44s\n",
      "464:\tlearn: 0.1070441\ttotal: 3m 14s\tremaining: 3m 43s\n",
      "465:\tlearn: 0.1069978\ttotal: 3m 14s\tremaining: 3m 43s\n",
      "466:\tlearn: 0.1069188\ttotal: 3m 15s\tremaining: 3m 42s\n",
      "467:\tlearn: 0.1068079\ttotal: 3m 15s\tremaining: 3m 42s\n",
      "468:\tlearn: 0.1067617\ttotal: 3m 15s\tremaining: 3m 41s\n",
      "469:\tlearn: 0.1065393\ttotal: 3m 16s\tremaining: 3m 41s\n",
      "470:\tlearn: 0.1064956\ttotal: 3m 16s\tremaining: 3m 40s\n",
      "471:\tlearn: 0.1064102\ttotal: 3m 17s\tremaining: 3m 40s\n",
      "472:\tlearn: 0.1062033\ttotal: 3m 17s\tremaining: 3m 40s\n",
      "473:\tlearn: 0.1060955\ttotal: 3m 18s\tremaining: 3m 39s\n",
      "474:\tlearn: 0.1059796\ttotal: 3m 18s\tremaining: 3m 39s\n",
      "475:\tlearn: 0.1058446\ttotal: 3m 18s\tremaining: 3m 38s\n",
      "476:\tlearn: 0.1057979\ttotal: 3m 19s\tremaining: 3m 38s\n",
      "477:\tlearn: 0.1056999\ttotal: 3m 19s\tremaining: 3m 38s\n",
      "478:\tlearn: 0.1056462\ttotal: 3m 20s\tremaining: 3m 37s\n",
      "479:\tlearn: 0.1055709\ttotal: 3m 20s\tremaining: 3m 37s\n",
      "480:\tlearn: 0.1054672\ttotal: 3m 20s\tremaining: 3m 36s\n",
      "481:\tlearn: 0.1053225\ttotal: 3m 21s\tremaining: 3m 36s\n",
      "482:\tlearn: 0.1052770\ttotal: 3m 21s\tremaining: 3m 35s\n",
      "483:\tlearn: 0.1051487\ttotal: 3m 22s\tremaining: 3m 35s\n",
      "484:\tlearn: 0.1051069\ttotal: 3m 22s\tremaining: 3m 34s\n",
      "485:\tlearn: 0.1050632\ttotal: 3m 22s\tremaining: 3m 34s\n",
      "486:\tlearn: 0.1050034\ttotal: 3m 23s\tremaining: 3m 34s\n",
      "487:\tlearn: 0.1048338\ttotal: 3m 23s\tremaining: 3m 33s\n",
      "488:\tlearn: 0.1047434\ttotal: 3m 23s\tremaining: 3m 33s\n",
      "489:\tlearn: 0.1046992\ttotal: 3m 24s\tremaining: 3m 32s\n",
      "490:\tlearn: 0.1046548\ttotal: 3m 24s\tremaining: 3m 32s\n",
      "491:\tlearn: 0.1045008\ttotal: 3m 25s\tremaining: 3m 32s\n",
      "492:\tlearn: 0.1044589\ttotal: 3m 25s\tremaining: 3m 31s\n",
      "493:\tlearn: 0.1044161\ttotal: 3m 26s\tremaining: 3m 31s\n",
      "494:\tlearn: 0.1043631\ttotal: 3m 26s\tremaining: 3m 30s\n",
      "495:\tlearn: 0.1043186\ttotal: 3m 26s\tremaining: 3m 30s\n",
      "496:\tlearn: 0.1041971\ttotal: 3m 27s\tremaining: 3m 29s\n",
      "497:\tlearn: 0.1041236\ttotal: 3m 27s\tremaining: 3m 29s\n",
      "498:\tlearn: 0.1040832\ttotal: 3m 28s\tremaining: 3m 28s\n",
      "499:\tlearn: 0.1039688\ttotal: 3m 28s\tremaining: 3m 28s\n",
      "500:\tlearn: 0.1039282\ttotal: 3m 28s\tremaining: 3m 28s\n",
      "501:\tlearn: 0.1038860\ttotal: 3m 29s\tremaining: 3m 27s\n",
      "502:\tlearn: 0.1037477\ttotal: 3m 29s\tremaining: 3m 27s\n",
      "503:\tlearn: 0.1037066\ttotal: 3m 29s\tremaining: 3m 26s\n",
      "504:\tlearn: 0.1036427\ttotal: 3m 30s\tremaining: 3m 26s\n",
      "505:\tlearn: 0.1036013\ttotal: 3m 30s\tremaining: 3m 25s\n",
      "506:\tlearn: 0.1033940\ttotal: 3m 31s\tremaining: 3m 25s\n",
      "507:\tlearn: 0.1033191\ttotal: 3m 31s\tremaining: 3m 24s\n",
      "508:\tlearn: 0.1032756\ttotal: 3m 31s\tremaining: 3m 24s\n",
      "509:\tlearn: 0.1032350\ttotal: 3m 32s\tremaining: 3m 23s\n",
      "510:\tlearn: 0.1031357\ttotal: 3m 32s\tremaining: 3m 23s\n",
      "511:\tlearn: 0.1030942\ttotal: 3m 32s\tremaining: 3m 22s\n",
      "512:\tlearn: 0.1029934\ttotal: 3m 33s\tremaining: 3m 22s\n",
      "513:\tlearn: 0.1027588\ttotal: 3m 33s\tremaining: 3m 21s\n",
      "514:\tlearn: 0.1027157\ttotal: 3m 33s\tremaining: 3m 21s\n",
      "515:\tlearn: 0.1025824\ttotal: 3m 34s\tremaining: 3m 21s\n",
      "516:\tlearn: 0.1025399\ttotal: 3m 34s\tremaining: 3m 20s\n",
      "517:\tlearn: 0.1024993\ttotal: 3m 35s\tremaining: 3m 20s\n",
      "518:\tlearn: 0.1024543\ttotal: 3m 35s\tremaining: 3m 19s\n",
      "519:\tlearn: 0.1024135\ttotal: 3m 35s\tremaining: 3m 19s\n",
      "520:\tlearn: 0.1023712\ttotal: 3m 36s\tremaining: 3m 18s\n",
      "521:\tlearn: 0.1023299\ttotal: 3m 36s\tremaining: 3m 18s\n",
      "522:\tlearn: 0.1021805\ttotal: 3m 37s\tremaining: 3m 17s\n",
      "523:\tlearn: 0.1021382\ttotal: 3m 37s\tremaining: 3m 17s\n",
      "524:\tlearn: 0.1020968\ttotal: 3m 37s\tremaining: 3m 17s\n",
      "525:\tlearn: 0.1020558\ttotal: 3m 38s\tremaining: 3m 16s\n",
      "526:\tlearn: 0.1020132\ttotal: 3m 38s\tremaining: 3m 16s\n",
      "527:\tlearn: 0.1018880\ttotal: 3m 39s\tremaining: 3m 15s\n",
      "528:\tlearn: 0.1018458\ttotal: 3m 39s\tremaining: 3m 15s\n",
      "529:\tlearn: 0.1018048\ttotal: 3m 39s\tremaining: 3m 14s\n",
      "530:\tlearn: 0.1017643\ttotal: 3m 40s\tremaining: 3m 14s\n",
      "531:\tlearn: 0.1017228\ttotal: 3m 40s\tremaining: 3m 13s\n",
      "532:\tlearn: 0.1016818\ttotal: 3m 40s\tremaining: 3m 13s\n",
      "533:\tlearn: 0.1016420\ttotal: 3m 41s\tremaining: 3m 13s\n",
      "534:\tlearn: 0.1013177\ttotal: 3m 41s\tremaining: 3m 12s\n",
      "535:\tlearn: 0.1012775\ttotal: 3m 42s\tremaining: 3m 12s\n",
      "536:\tlearn: 0.1011178\ttotal: 3m 42s\tremaining: 3m 12s\n",
      "537:\tlearn: 0.1010768\ttotal: 3m 43s\tremaining: 3m 12s\n",
      "538:\tlearn: 0.1009883\ttotal: 3m 44s\tremaining: 3m 11s\n",
      "539:\tlearn: 0.1008452\ttotal: 3m 45s\tremaining: 3m 11s\n",
      "540:\tlearn: 0.1007247\ttotal: 3m 45s\tremaining: 3m 11s\n",
      "541:\tlearn: 0.1006843\ttotal: 3m 46s\tremaining: 3m 11s\n",
      "542:\tlearn: 0.1006449\ttotal: 3m 47s\tremaining: 3m 11s\n",
      "543:\tlearn: 0.1005092\ttotal: 3m 48s\tremaining: 3m 11s\n",
      "544:\tlearn: 0.1004690\ttotal: 3m 48s\tremaining: 3m 10s\n",
      "545:\tlearn: 0.1004166\ttotal: 3m 49s\tremaining: 3m 10s\n",
      "546:\tlearn: 0.1003784\ttotal: 3m 50s\tremaining: 3m 10s\n",
      "547:\tlearn: 0.1000741\ttotal: 3m 51s\tremaining: 3m 10s\n",
      "548:\tlearn: 0.0998306\ttotal: 3m 51s\tremaining: 3m 10s\n",
      "549:\tlearn: 0.0996922\ttotal: 3m 52s\tremaining: 3m 10s\n",
      "550:\tlearn: 0.0996249\ttotal: 3m 53s\tremaining: 3m 10s\n",
      "551:\tlearn: 0.0995869\ttotal: 3m 53s\tremaining: 3m 9s\n",
      "552:\tlearn: 0.0994676\ttotal: 3m 54s\tremaining: 3m 9s\n",
      "553:\tlearn: 0.0993262\ttotal: 3m 55s\tremaining: 3m 9s\n",
      "554:\tlearn: 0.0991968\ttotal: 3m 56s\tremaining: 3m 9s\n",
      "555:\tlearn: 0.0991578\ttotal: 3m 56s\tremaining: 3m 9s\n",
      "556:\tlearn: 0.0991187\ttotal: 3m 57s\tremaining: 3m 8s\n",
      "557:\tlearn: 0.0990800\ttotal: 3m 58s\tremaining: 3m 8s\n",
      "558:\tlearn: 0.0989632\ttotal: 3m 58s\tremaining: 3m 8s\n",
      "559:\tlearn: 0.0989265\ttotal: 3m 59s\tremaining: 3m 8s\n",
      "560:\tlearn: 0.0988729\ttotal: 4m\tremaining: 3m 8s\n",
      "561:\tlearn: 0.0988144\ttotal: 4m 1s\tremaining: 3m 7s\n",
      "562:\tlearn: 0.0987765\ttotal: 4m 1s\tremaining: 3m 7s\n",
      "563:\tlearn: 0.0987133\ttotal: 4m 2s\tremaining: 3m 7s\n",
      "564:\tlearn: 0.0985173\ttotal: 4m 3s\tremaining: 3m 7s\n",
      "565:\tlearn: 0.0982570\ttotal: 4m 3s\tremaining: 3m 7s\n",
      "566:\tlearn: 0.0982209\ttotal: 4m 4s\tremaining: 3m 6s\n",
      "567:\tlearn: 0.0980997\ttotal: 4m 5s\tremaining: 3m 6s\n",
      "568:\tlearn: 0.0979803\ttotal: 4m 6s\tremaining: 3m 6s\n",
      "569:\tlearn: 0.0979438\ttotal: 4m 6s\tremaining: 3m 6s\n",
      "570:\tlearn: 0.0978498\ttotal: 4m 7s\tremaining: 3m 6s\n",
      "571:\tlearn: 0.0977900\ttotal: 4m 8s\tremaining: 3m 5s\n",
      "572:\tlearn: 0.0977526\ttotal: 4m 9s\tremaining: 3m 5s\n",
      "573:\tlearn: 0.0977143\ttotal: 4m 9s\tremaining: 3m 5s\n",
      "574:\tlearn: 0.0976627\ttotal: 4m 10s\tremaining: 3m 5s\n",
      "575:\tlearn: 0.0975674\ttotal: 4m 11s\tremaining: 3m 4s\n",
      "576:\tlearn: 0.0975306\ttotal: 4m 11s\tremaining: 3m 4s\n",
      "577:\tlearn: 0.0973426\ttotal: 4m 12s\tremaining: 3m 4s\n",
      "578:\tlearn: 0.0970958\ttotal: 4m 13s\tremaining: 3m 4s\n",
      "579:\tlearn: 0.0969638\ttotal: 4m 14s\tremaining: 3m 4s\n",
      "580:\tlearn: 0.0966762\ttotal: 4m 14s\tremaining: 3m 3s\n",
      "581:\tlearn: 0.0966396\ttotal: 4m 15s\tremaining: 3m 3s\n",
      "582:\tlearn: 0.0966018\ttotal: 4m 16s\tremaining: 3m 3s\n",
      "583:\tlearn: 0.0965644\ttotal: 4m 17s\tremaining: 3m 3s\n",
      "584:\tlearn: 0.0965289\ttotal: 4m 17s\tremaining: 3m 2s\n",
      "585:\tlearn: 0.0964451\ttotal: 4m 18s\tremaining: 3m 2s\n",
      "586:\tlearn: 0.0964086\ttotal: 4m 19s\tremaining: 3m 2s\n",
      "587:\tlearn: 0.0963668\ttotal: 4m 20s\tremaining: 3m 2s\n",
      "588:\tlearn: 0.0963303\ttotal: 4m 20s\tremaining: 3m 1s\n",
      "589:\tlearn: 0.0962868\ttotal: 4m 21s\tremaining: 3m 1s\n",
      "590:\tlearn: 0.0962492\ttotal: 4m 22s\tremaining: 3m 1s\n",
      "591:\tlearn: 0.0962115\ttotal: 4m 22s\tremaining: 3m 1s\n",
      "592:\tlearn: 0.0961739\ttotal: 4m 23s\tremaining: 3m\n",
      "593:\tlearn: 0.0961377\ttotal: 4m 24s\tremaining: 3m\n",
      "594:\tlearn: 0.0961005\ttotal: 4m 25s\tremaining: 3m\n",
      "595:\tlearn: 0.0960644\ttotal: 4m 25s\tremaining: 3m\n",
      "596:\tlearn: 0.0960256\ttotal: 4m 26s\tremaining: 2m 59s\n",
      "597:\tlearn: 0.0959342\ttotal: 4m 27s\tremaining: 2m 59s\n",
      "598:\tlearn: 0.0957594\ttotal: 4m 27s\tremaining: 2m 59s\n",
      "599:\tlearn: 0.0957215\ttotal: 4m 28s\tremaining: 2m 59s\n",
      "600:\tlearn: 0.0956869\ttotal: 4m 29s\tremaining: 2m 58s\n",
      "601:\tlearn: 0.0956492\ttotal: 4m 29s\tremaining: 2m 58s\n",
      "602:\tlearn: 0.0954796\ttotal: 4m 30s\tremaining: 2m 58s\n",
      "603:\tlearn: 0.0954445\ttotal: 4m 31s\tremaining: 2m 57s\n",
      "604:\tlearn: 0.0954077\ttotal: 4m 32s\tremaining: 2m 57s\n",
      "605:\tlearn: 0.0953063\ttotal: 4m 32s\tremaining: 2m 57s\n",
      "606:\tlearn: 0.0952711\ttotal: 4m 33s\tremaining: 2m 57s\n",
      "607:\tlearn: 0.0952348\ttotal: 4m 34s\tremaining: 2m 56s\n",
      "608:\tlearn: 0.0951988\ttotal: 4m 34s\tremaining: 2m 56s\n",
      "609:\tlearn: 0.0951629\ttotal: 4m 35s\tremaining: 2m 56s\n",
      "610:\tlearn: 0.0951080\ttotal: 4m 36s\tremaining: 2m 56s\n",
      "611:\tlearn: 0.0950489\ttotal: 4m 37s\tremaining: 2m 55s\n",
      "612:\tlearn: 0.0950141\ttotal: 4m 37s\tremaining: 2m 55s\n",
      "613:\tlearn: 0.0949800\ttotal: 4m 38s\tremaining: 2m 55s\n",
      "614:\tlearn: 0.0948979\ttotal: 4m 39s\tremaining: 2m 54s\n",
      "615:\tlearn: 0.0947793\ttotal: 4m 39s\tremaining: 2m 54s\n",
      "616:\tlearn: 0.0947218\ttotal: 4m 40s\tremaining: 2m 54s\n",
      "617:\tlearn: 0.0946877\ttotal: 4m 41s\tremaining: 2m 53s\n",
      "618:\tlearn: 0.0946066\ttotal: 4m 42s\tremaining: 2m 53s\n",
      "619:\tlearn: 0.0945602\ttotal: 4m 42s\tremaining: 2m 53s\n",
      "620:\tlearn: 0.0944304\ttotal: 4m 43s\tremaining: 2m 53s\n",
      "621:\tlearn: 0.0940643\ttotal: 4m 44s\tremaining: 2m 52s\n",
      "622:\tlearn: 0.0940185\ttotal: 4m 44s\tremaining: 2m 52s\n",
      "623:\tlearn: 0.0936918\ttotal: 4m 45s\tremaining: 2m 52s\n",
      "624:\tlearn: 0.0936573\ttotal: 4m 46s\tremaining: 2m 51s\n",
      "625:\tlearn: 0.0936225\ttotal: 4m 47s\tremaining: 2m 51s\n",
      "626:\tlearn: 0.0935424\ttotal: 4m 47s\tremaining: 2m 51s\n",
      "627:\tlearn: 0.0932716\ttotal: 4m 48s\tremaining: 2m 50s\n",
      "628:\tlearn: 0.0932185\ttotal: 4m 49s\tremaining: 2m 50s\n",
      "629:\tlearn: 0.0931659\ttotal: 4m 49s\tremaining: 2m 50s\n",
      "630:\tlearn: 0.0931313\ttotal: 4m 50s\tremaining: 2m 49s\n",
      "631:\tlearn: 0.0930263\ttotal: 4m 51s\tremaining: 2m 49s\n",
      "632:\tlearn: 0.0929422\ttotal: 4m 51s\tremaining: 2m 49s\n",
      "633:\tlearn: 0.0929068\ttotal: 4m 52s\tremaining: 2m 48s\n",
      "634:\tlearn: 0.0928732\ttotal: 4m 53s\tremaining: 2m 48s\n",
      "635:\tlearn: 0.0927689\ttotal: 4m 54s\tremaining: 2m 48s\n",
      "636:\tlearn: 0.0926600\ttotal: 4m 54s\tremaining: 2m 47s\n",
      "637:\tlearn: 0.0926279\ttotal: 4m 55s\tremaining: 2m 47s\n",
      "638:\tlearn: 0.0925713\ttotal: 4m 56s\tremaining: 2m 47s\n",
      "639:\tlearn: 0.0924747\ttotal: 4m 56s\tremaining: 2m 47s\n",
      "640:\tlearn: 0.0924420\ttotal: 4m 57s\tremaining: 2m 46s\n",
      "641:\tlearn: 0.0921948\ttotal: 4m 58s\tremaining: 2m 46s\n",
      "642:\tlearn: 0.0921277\ttotal: 4m 59s\tremaining: 2m 46s\n",
      "643:\tlearn: 0.0920205\ttotal: 4m 59s\tremaining: 2m 45s\n",
      "644:\tlearn: 0.0919687\ttotal: 5m\tremaining: 2m 45s\n",
      "645:\tlearn: 0.0919365\ttotal: 5m 1s\tremaining: 2m 45s\n",
      "646:\tlearn: 0.0918958\ttotal: 5m 1s\tremaining: 2m 44s\n",
      "647:\tlearn: 0.0918636\ttotal: 5m 2s\tremaining: 2m 44s\n",
      "648:\tlearn: 0.0917624\ttotal: 5m 3s\tremaining: 2m 44s\n",
      "649:\tlearn: 0.0917290\ttotal: 5m 3s\tremaining: 2m 43s\n",
      "650:\tlearn: 0.0916161\ttotal: 5m 4s\tremaining: 2m 43s\n",
      "651:\tlearn: 0.0915830\ttotal: 5m 5s\tremaining: 2m 42s\n",
      "652:\tlearn: 0.0915498\ttotal: 5m 6s\tremaining: 2m 42s\n",
      "653:\tlearn: 0.0915182\ttotal: 5m 6s\tremaining: 2m 42s\n",
      "654:\tlearn: 0.0914847\ttotal: 5m 7s\tremaining: 2m 41s\n",
      "655:\tlearn: 0.0914511\ttotal: 5m 8s\tremaining: 2m 41s\n",
      "656:\tlearn: 0.0912611\ttotal: 5m 8s\tremaining: 2m 41s\n",
      "657:\tlearn: 0.0912273\ttotal: 5m 9s\tremaining: 2m 40s\n",
      "658:\tlearn: 0.0911966\ttotal: 5m 10s\tremaining: 2m 40s\n",
      "659:\tlearn: 0.0911636\ttotal: 5m 11s\tremaining: 2m 40s\n",
      "660:\tlearn: 0.0911086\ttotal: 5m 11s\tremaining: 2m 39s\n",
      "661:\tlearn: 0.0910266\ttotal: 5m 12s\tremaining: 2m 39s\n",
      "662:\tlearn: 0.0908952\ttotal: 5m 13s\tremaining: 2m 39s\n",
      "663:\tlearn: 0.0908614\ttotal: 5m 13s\tremaining: 2m 38s\n",
      "664:\tlearn: 0.0908289\ttotal: 5m 14s\tremaining: 2m 38s\n",
      "665:\tlearn: 0.0906791\ttotal: 5m 15s\tremaining: 2m 38s\n",
      "666:\tlearn: 0.0906478\ttotal: 5m 15s\tremaining: 2m 37s\n",
      "667:\tlearn: 0.0906137\ttotal: 5m 16s\tremaining: 2m 37s\n",
      "668:\tlearn: 0.0905184\ttotal: 5m 17s\tremaining: 2m 37s\n",
      "669:\tlearn: 0.0904844\ttotal: 5m 18s\tremaining: 2m 36s\n",
      "670:\tlearn: 0.0904527\ttotal: 5m 18s\tremaining: 2m 36s\n",
      "671:\tlearn: 0.0904204\ttotal: 5m 19s\tremaining: 2m 35s\n",
      "672:\tlearn: 0.0902437\ttotal: 5m 20s\tremaining: 2m 35s\n",
      "673:\tlearn: 0.0900215\ttotal: 5m 20s\tremaining: 2m 35s\n",
      "674:\tlearn: 0.0899893\ttotal: 5m 21s\tremaining: 2m 34s\n",
      "675:\tlearn: 0.0899555\ttotal: 5m 22s\tremaining: 2m 34s\n",
      "676:\tlearn: 0.0899227\ttotal: 5m 23s\tremaining: 2m 34s\n",
      "677:\tlearn: 0.0898909\ttotal: 5m 23s\tremaining: 2m 33s\n",
      "678:\tlearn: 0.0898570\ttotal: 5m 24s\tremaining: 2m 33s\n",
      "679:\tlearn: 0.0898252\ttotal: 5m 25s\tremaining: 2m 32s\n",
      "680:\tlearn: 0.0897307\ttotal: 5m 25s\tremaining: 2m 32s\n",
      "681:\tlearn: 0.0896968\ttotal: 5m 26s\tremaining: 2m 32s\n",
      "682:\tlearn: 0.0896407\ttotal: 5m 27s\tremaining: 2m 31s\n",
      "683:\tlearn: 0.0896088\ttotal: 5m 27s\tremaining: 2m 31s\n",
      "684:\tlearn: 0.0895754\ttotal: 5m 28s\tremaining: 2m 31s\n",
      "685:\tlearn: 0.0894869\ttotal: 5m 29s\tremaining: 2m 30s\n",
      "686:\tlearn: 0.0894555\ttotal: 5m 30s\tremaining: 2m 30s\n",
      "687:\tlearn: 0.0894211\ttotal: 5m 30s\tremaining: 2m 29s\n",
      "688:\tlearn: 0.0893607\ttotal: 5m 31s\tremaining: 2m 29s\n",
      "689:\tlearn: 0.0893020\ttotal: 5m 32s\tremaining: 2m 29s\n",
      "690:\tlearn: 0.0892271\ttotal: 5m 32s\tremaining: 2m 28s\n",
      "691:\tlearn: 0.0891978\ttotal: 5m 33s\tremaining: 2m 28s\n",
      "692:\tlearn: 0.0891619\ttotal: 5m 34s\tremaining: 2m 28s\n",
      "693:\tlearn: 0.0891138\ttotal: 5m 34s\tremaining: 2m 27s\n",
      "694:\tlearn: 0.0889597\ttotal: 5m 35s\tremaining: 2m 27s\n",
      "695:\tlearn: 0.0889295\ttotal: 5m 36s\tremaining: 2m 26s\n",
      "696:\tlearn: 0.0888975\ttotal: 5m 37s\tremaining: 2m 26s\n",
      "697:\tlearn: 0.0888650\ttotal: 5m 37s\tremaining: 2m 26s\n",
      "698:\tlearn: 0.0887698\ttotal: 5m 38s\tremaining: 2m 25s\n",
      "699:\tlearn: 0.0887402\ttotal: 5m 39s\tremaining: 2m 25s\n",
      "700:\tlearn: 0.0886284\ttotal: 5m 39s\tremaining: 2m 24s\n",
      "701:\tlearn: 0.0885945\ttotal: 5m 40s\tremaining: 2m 24s\n",
      "702:\tlearn: 0.0885654\ttotal: 5m 41s\tremaining: 2m 24s\n",
      "703:\tlearn: 0.0884905\ttotal: 5m 41s\tremaining: 2m 23s\n",
      "704:\tlearn: 0.0884602\ttotal: 5m 42s\tremaining: 2m 23s\n",
      "705:\tlearn: 0.0884310\ttotal: 5m 43s\tremaining: 2m 22s\n",
      "706:\tlearn: 0.0884014\ttotal: 5m 44s\tremaining: 2m 22s\n",
      "707:\tlearn: 0.0883454\ttotal: 5m 44s\tremaining: 2m 22s\n",
      "708:\tlearn: 0.0881849\ttotal: 5m 45s\tremaining: 2m 21s\n",
      "709:\tlearn: 0.0881574\ttotal: 5m 46s\tremaining: 2m 21s\n",
      "710:\tlearn: 0.0880594\ttotal: 5m 46s\tremaining: 2m 21s\n",
      "711:\tlearn: 0.0880288\ttotal: 5m 47s\tremaining: 2m 20s\n",
      "712:\tlearn: 0.0879882\ttotal: 5m 48s\tremaining: 2m 20s\n",
      "713:\tlearn: 0.0879109\ttotal: 5m 49s\tremaining: 2m 19s\n",
      "714:\tlearn: 0.0876966\ttotal: 5m 49s\tremaining: 2m 19s\n",
      "715:\tlearn: 0.0876662\ttotal: 5m 50s\tremaining: 2m 18s\n",
      "716:\tlearn: 0.0876378\ttotal: 5m 51s\tremaining: 2m 18s\n",
      "717:\tlearn: 0.0875498\ttotal: 5m 51s\tremaining: 2m 18s\n",
      "718:\tlearn: 0.0874375\ttotal: 5m 52s\tremaining: 2m 17s\n",
      "719:\tlearn: 0.0873793\ttotal: 5m 53s\tremaining: 2m 17s\n",
      "720:\tlearn: 0.0873271\ttotal: 5m 54s\tremaining: 2m 17s\n",
      "721:\tlearn: 0.0872193\ttotal: 5m 54s\tremaining: 2m 16s\n",
      "722:\tlearn: 0.0870227\ttotal: 5m 55s\tremaining: 2m 16s\n",
      "723:\tlearn: 0.0868543\ttotal: 5m 56s\tremaining: 2m 15s\n",
      "724:\tlearn: 0.0867524\ttotal: 5m 56s\tremaining: 2m 15s\n",
      "725:\tlearn: 0.0867239\ttotal: 5m 57s\tremaining: 2m 14s\n",
      "726:\tlearn: 0.0866862\ttotal: 5m 58s\tremaining: 2m 14s\n",
      "727:\tlearn: 0.0865910\ttotal: 5m 59s\tremaining: 2m 14s\n",
      "728:\tlearn: 0.0865062\ttotal: 5m 59s\tremaining: 2m 13s\n",
      "729:\tlearn: 0.0864773\ttotal: 6m\tremaining: 2m 13s\n",
      "730:\tlearn: 0.0864040\ttotal: 6m 1s\tremaining: 2m 12s\n",
      "731:\tlearn: 0.0863630\ttotal: 6m 1s\tremaining: 2m 12s\n",
      "732:\tlearn: 0.0863334\ttotal: 6m 2s\tremaining: 2m 12s\n",
      "733:\tlearn: 0.0863040\ttotal: 6m 3s\tremaining: 2m 11s\n",
      "734:\tlearn: 0.0860700\ttotal: 6m 4s\tremaining: 2m 11s\n",
      "735:\tlearn: 0.0860199\ttotal: 6m 4s\tremaining: 2m 10s\n",
      "736:\tlearn: 0.0859897\ttotal: 6m 5s\tremaining: 2m 10s\n",
      "737:\tlearn: 0.0858620\ttotal: 6m 6s\tremaining: 2m 9s\n",
      "738:\tlearn: 0.0858330\ttotal: 6m 6s\tremaining: 2m 9s\n",
      "739:\tlearn: 0.0858003\ttotal: 6m 7s\tremaining: 2m 9s\n",
      "740:\tlearn: 0.0857732\ttotal: 6m 8s\tremaining: 2m 8s\n",
      "741:\tlearn: 0.0856581\ttotal: 6m 9s\tremaining: 2m 8s\n",
      "742:\tlearn: 0.0855504\ttotal: 6m 9s\tremaining: 2m 7s\n",
      "743:\tlearn: 0.0854593\ttotal: 6m 10s\tremaining: 2m 7s\n",
      "744:\tlearn: 0.0853742\ttotal: 6m 11s\tremaining: 2m 7s\n",
      "745:\tlearn: 0.0853242\ttotal: 6m 11s\tremaining: 2m 6s\n",
      "746:\tlearn: 0.0852954\ttotal: 6m 12s\tremaining: 2m 6s\n",
      "747:\tlearn: 0.0852663\ttotal: 6m 13s\tremaining: 2m 5s\n",
      "748:\tlearn: 0.0852366\ttotal: 6m 14s\tremaining: 2m 5s\n",
      "749:\tlearn: 0.0852076\ttotal: 6m 14s\tremaining: 2m 4s\n",
      "750:\tlearn: 0.0851788\ttotal: 6m 15s\tremaining: 2m 4s\n",
      "751:\tlearn: 0.0851381\ttotal: 6m 16s\tremaining: 2m 4s\n",
      "752:\tlearn: 0.0849809\ttotal: 6m 16s\tremaining: 2m 3s\n",
      "753:\tlearn: 0.0849509\ttotal: 6m 17s\tremaining: 2m 3s\n",
      "754:\tlearn: 0.0848958\ttotal: 6m 18s\tremaining: 2m 2s\n",
      "755:\tlearn: 0.0848677\ttotal: 6m 19s\tremaining: 2m 2s\n",
      "756:\tlearn: 0.0848377\ttotal: 6m 19s\tremaining: 2m 1s\n",
      "757:\tlearn: 0.0847666\ttotal: 6m 20s\tremaining: 2m 1s\n",
      "758:\tlearn: 0.0847209\ttotal: 6m 21s\tremaining: 2m 1s\n",
      "759:\tlearn: 0.0846934\ttotal: 6m 21s\tremaining: 2m\n",
      "760:\tlearn: 0.0846644\ttotal: 6m 22s\tremaining: 2m\n",
      "761:\tlearn: 0.0846343\ttotal: 6m 23s\tremaining: 1m 59s\n",
      "762:\tlearn: 0.0846060\ttotal: 6m 24s\tremaining: 1m 59s\n",
      "763:\tlearn: 0.0845009\ttotal: 6m 24s\tremaining: 1m 58s\n",
      "764:\tlearn: 0.0844725\ttotal: 6m 25s\tremaining: 1m 58s\n",
      "765:\tlearn: 0.0843974\ttotal: 6m 26s\tremaining: 1m 58s\n",
      "766:\tlearn: 0.0842515\ttotal: 6m 27s\tremaining: 1m 57s\n",
      "767:\tlearn: 0.0842252\ttotal: 6m 27s\tremaining: 1m 57s\n",
      "768:\tlearn: 0.0841756\ttotal: 6m 28s\tremaining: 1m 56s\n",
      "769:\tlearn: 0.0841471\ttotal: 6m 28s\tremaining: 1m 56s\n",
      "770:\tlearn: 0.0841170\ttotal: 6m 28s\tremaining: 1m 55s\n",
      "771:\tlearn: 0.0840070\ttotal: 6m 29s\tremaining: 1m 54s\n",
      "772:\tlearn: 0.0839792\ttotal: 6m 29s\tremaining: 1m 54s\n",
      "773:\tlearn: 0.0839482\ttotal: 6m 29s\tremaining: 1m 53s\n",
      "774:\tlearn: 0.0839195\ttotal: 6m 30s\tremaining: 1m 53s\n",
      "775:\tlearn: 0.0838917\ttotal: 6m 30s\tremaining: 1m 52s\n",
      "776:\tlearn: 0.0838635\ttotal: 6m 31s\tremaining: 1m 52s\n",
      "777:\tlearn: 0.0838356\ttotal: 6m 31s\tremaining: 1m 51s\n",
      "778:\tlearn: 0.0837615\ttotal: 6m 31s\tremaining: 1m 51s\n",
      "779:\tlearn: 0.0836370\ttotal: 6m 32s\tremaining: 1m 50s\n",
      "780:\tlearn: 0.0836073\ttotal: 6m 32s\tremaining: 1m 50s\n",
      "781:\tlearn: 0.0834648\ttotal: 6m 32s\tremaining: 1m 49s\n",
      "782:\tlearn: 0.0833236\ttotal: 6m 33s\tremaining: 1m 49s\n",
      "783:\tlearn: 0.0832947\ttotal: 6m 33s\tremaining: 1m 48s\n",
      "784:\tlearn: 0.0832555\ttotal: 6m 34s\tremaining: 1m 47s\n",
      "785:\tlearn: 0.0832268\ttotal: 6m 34s\tremaining: 1m 47s\n",
      "786:\tlearn: 0.0831234\ttotal: 6m 34s\tremaining: 1m 46s\n",
      "787:\tlearn: 0.0830961\ttotal: 6m 35s\tremaining: 1m 46s\n",
      "788:\tlearn: 0.0830684\ttotal: 6m 35s\tremaining: 1m 45s\n",
      "789:\tlearn: 0.0830398\ttotal: 6m 35s\tremaining: 1m 45s\n",
      "790:\tlearn: 0.0829483\ttotal: 6m 36s\tremaining: 1m 44s\n",
      "791:\tlearn: 0.0829198\ttotal: 6m 36s\tremaining: 1m 44s\n",
      "792:\tlearn: 0.0828940\ttotal: 6m 37s\tremaining: 1m 43s\n",
      "793:\tlearn: 0.0828267\ttotal: 6m 38s\tremaining: 1m 43s\n",
      "794:\tlearn: 0.0828002\ttotal: 6m 38s\tremaining: 1m 42s\n",
      "795:\tlearn: 0.0826919\ttotal: 6m 39s\tremaining: 1m 42s\n",
      "796:\tlearn: 0.0826664\ttotal: 6m 40s\tremaining: 1m 41s\n",
      "797:\tlearn: 0.0824954\ttotal: 6m 40s\tremaining: 1m 41s\n",
      "798:\tlearn: 0.0824346\ttotal: 6m 41s\tremaining: 1m 41s\n",
      "799:\tlearn: 0.0823965\ttotal: 6m 42s\tremaining: 1m 40s\n",
      "800:\tlearn: 0.0822488\ttotal: 6m 43s\tremaining: 1m 40s\n",
      "801:\tlearn: 0.0820568\ttotal: 6m 43s\tremaining: 1m 39s\n",
      "802:\tlearn: 0.0820168\ttotal: 6m 44s\tremaining: 1m 39s\n",
      "803:\tlearn: 0.0819668\ttotal: 6m 45s\tremaining: 1m 38s\n",
      "804:\tlearn: 0.0819383\ttotal: 6m 45s\tremaining: 1m 38s\n",
      "805:\tlearn: 0.0818760\ttotal: 6m 46s\tremaining: 1m 37s\n",
      "806:\tlearn: 0.0817397\ttotal: 6m 47s\tremaining: 1m 37s\n",
      "807:\tlearn: 0.0816604\ttotal: 6m 47s\tremaining: 1m 36s\n",
      "808:\tlearn: 0.0816342\ttotal: 6m 48s\tremaining: 1m 36s\n",
      "809:\tlearn: 0.0815832\ttotal: 6m 49s\tremaining: 1m 36s\n",
      "810:\tlearn: 0.0815566\ttotal: 6m 50s\tremaining: 1m 35s\n",
      "811:\tlearn: 0.0815320\ttotal: 6m 50s\tremaining: 1m 35s\n",
      "812:\tlearn: 0.0813425\ttotal: 6m 51s\tremaining: 1m 34s\n",
      "813:\tlearn: 0.0812735\ttotal: 6m 52s\tremaining: 1m 34s\n",
      "814:\tlearn: 0.0812471\ttotal: 6m 53s\tremaining: 1m 33s\n",
      "815:\tlearn: 0.0811689\ttotal: 6m 53s\tremaining: 1m 33s\n",
      "816:\tlearn: 0.0811410\ttotal: 6m 54s\tremaining: 1m 32s\n",
      "817:\tlearn: 0.0810130\ttotal: 6m 55s\tremaining: 1m 32s\n",
      "818:\tlearn: 0.0808770\ttotal: 6m 55s\tremaining: 1m 31s\n",
      "819:\tlearn: 0.0808520\ttotal: 6m 56s\tremaining: 1m 31s\n",
      "820:\tlearn: 0.0807751\ttotal: 6m 57s\tremaining: 1m 31s\n",
      "821:\tlearn: 0.0807490\ttotal: 6m 58s\tremaining: 1m 30s\n",
      "822:\tlearn: 0.0807230\ttotal: 6m 58s\tremaining: 1m 30s\n",
      "823:\tlearn: 0.0806661\ttotal: 6m 59s\tremaining: 1m 29s\n",
      "824:\tlearn: 0.0805807\ttotal: 7m\tremaining: 1m 29s\n",
      "825:\tlearn: 0.0805080\ttotal: 7m\tremaining: 1m 28s\n",
      "826:\tlearn: 0.0804753\ttotal: 7m 1s\tremaining: 1m 28s\n",
      "827:\tlearn: 0.0802867\ttotal: 7m 2s\tremaining: 1m 27s\n",
      "828:\tlearn: 0.0802315\ttotal: 7m 3s\tremaining: 1m 27s\n",
      "829:\tlearn: 0.0802056\ttotal: 7m 3s\tremaining: 1m 26s\n",
      "830:\tlearn: 0.0801053\ttotal: 7m 4s\tremaining: 1m 26s\n",
      "831:\tlearn: 0.0800788\ttotal: 7m 5s\tremaining: 1m 25s\n",
      "832:\tlearn: 0.0800105\ttotal: 7m 5s\tremaining: 1m 25s\n",
      "833:\tlearn: 0.0799280\ttotal: 7m 6s\tremaining: 1m 24s\n",
      "834:\tlearn: 0.0799027\ttotal: 7m 7s\tremaining: 1m 24s\n",
      "835:\tlearn: 0.0798762\ttotal: 7m 8s\tremaining: 1m 23s\n",
      "836:\tlearn: 0.0798220\ttotal: 7m 8s\tremaining: 1m 23s\n",
      "837:\tlearn: 0.0797958\ttotal: 7m 9s\tremaining: 1m 23s\n",
      "838:\tlearn: 0.0797707\ttotal: 7m 10s\tremaining: 1m 22s\n",
      "839:\tlearn: 0.0797439\ttotal: 7m 10s\tremaining: 1m 22s\n",
      "840:\tlearn: 0.0797191\ttotal: 7m 11s\tremaining: 1m 21s\n",
      "841:\tlearn: 0.0796941\ttotal: 7m 12s\tremaining: 1m 21s\n",
      "842:\tlearn: 0.0796675\ttotal: 7m 13s\tremaining: 1m 20s\n",
      "843:\tlearn: 0.0795973\ttotal: 7m 13s\tremaining: 1m 20s\n",
      "844:\tlearn: 0.0795721\ttotal: 7m 14s\tremaining: 1m 19s\n",
      "845:\tlearn: 0.0795475\ttotal: 7m 15s\tremaining: 1m 19s\n",
      "846:\tlearn: 0.0795221\ttotal: 7m 15s\tremaining: 1m 18s\n",
      "847:\tlearn: 0.0794947\ttotal: 7m 16s\tremaining: 1m 18s\n",
      "848:\tlearn: 0.0794697\ttotal: 7m 17s\tremaining: 1m 17s\n",
      "849:\tlearn: 0.0793485\ttotal: 7m 18s\tremaining: 1m 17s\n",
      "850:\tlearn: 0.0791439\ttotal: 7m 18s\tremaining: 1m 16s\n",
      "851:\tlearn: 0.0791192\ttotal: 7m 19s\tremaining: 1m 16s\n",
      "852:\tlearn: 0.0790923\ttotal: 7m 20s\tremaining: 1m 15s\n",
      "853:\tlearn: 0.0790455\ttotal: 7m 20s\tremaining: 1m 15s\n",
      "854:\tlearn: 0.0789949\ttotal: 7m 21s\tremaining: 1m 14s\n",
      "855:\tlearn: 0.0789685\ttotal: 7m 22s\tremaining: 1m 14s\n",
      "856:\tlearn: 0.0789218\ttotal: 7m 22s\tremaining: 1m 13s\n",
      "857:\tlearn: 0.0788956\ttotal: 7m 23s\tremaining: 1m 13s\n",
      "858:\tlearn: 0.0788705\ttotal: 7m 24s\tremaining: 1m 12s\n",
      "859:\tlearn: 0.0788455\ttotal: 7m 25s\tremaining: 1m 12s\n",
      "860:\tlearn: 0.0787436\ttotal: 7m 25s\tremaining: 1m 11s\n",
      "861:\tlearn: 0.0786651\ttotal: 7m 26s\tremaining: 1m 11s\n",
      "862:\tlearn: 0.0786394\ttotal: 7m 27s\tremaining: 1m 10s\n",
      "863:\tlearn: 0.0785646\ttotal: 7m 27s\tremaining: 1m 10s\n",
      "864:\tlearn: 0.0784399\ttotal: 7m 28s\tremaining: 1m 10s\n",
      "865:\tlearn: 0.0784131\ttotal: 7m 29s\tremaining: 1m 9s\n",
      "866:\tlearn: 0.0783884\ttotal: 7m 30s\tremaining: 1m 9s\n",
      "867:\tlearn: 0.0782859\ttotal: 7m 30s\tremaining: 1m 8s\n",
      "868:\tlearn: 0.0782608\ttotal: 7m 31s\tremaining: 1m 8s\n",
      "869:\tlearn: 0.0781009\ttotal: 7m 32s\tremaining: 1m 7s\n",
      "870:\tlearn: 0.0780293\ttotal: 7m 32s\tremaining: 1m 7s\n",
      "871:\tlearn: 0.0780051\ttotal: 7m 33s\tremaining: 1m 6s\n",
      "872:\tlearn: 0.0779788\ttotal: 7m 34s\tremaining: 1m 6s\n",
      "873:\tlearn: 0.0779143\ttotal: 7m 34s\tremaining: 1m 5s\n",
      "874:\tlearn: 0.0778899\ttotal: 7m 35s\tremaining: 1m 5s\n",
      "875:\tlearn: 0.0778663\ttotal: 7m 36s\tremaining: 1m 4s\n",
      "876:\tlearn: 0.0778065\ttotal: 7m 37s\tremaining: 1m 4s\n",
      "877:\tlearn: 0.0777805\ttotal: 7m 37s\tremaining: 1m 3s\n",
      "878:\tlearn: 0.0777558\ttotal: 7m 38s\tremaining: 1m 3s\n",
      "879:\tlearn: 0.0776950\ttotal: 7m 39s\tremaining: 1m 2s\n",
      "880:\tlearn: 0.0776595\ttotal: 7m 39s\tremaining: 1m 2s\n",
      "881:\tlearn: 0.0775467\ttotal: 7m 40s\tremaining: 1m 1s\n",
      "882:\tlearn: 0.0775228\ttotal: 7m 41s\tremaining: 1m 1s\n",
      "883:\tlearn: 0.0774630\ttotal: 7m 42s\tremaining: 1m\n",
      "884:\tlearn: 0.0774383\ttotal: 7m 42s\tremaining: 1m\n",
      "885:\tlearn: 0.0773672\ttotal: 7m 43s\tremaining: 59.6s\n",
      "886:\tlearn: 0.0773404\ttotal: 7m 44s\tremaining: 59.1s\n",
      "887:\tlearn: 0.0773162\ttotal: 7m 44s\tremaining: 58.6s\n",
      "888:\tlearn: 0.0772794\ttotal: 7m 45s\tremaining: 58.1s\n",
      "889:\tlearn: 0.0772556\ttotal: 7m 46s\tremaining: 57.6s\n",
      "890:\tlearn: 0.0772315\ttotal: 7m 47s\tremaining: 57.1s\n",
      "891:\tlearn: 0.0771697\ttotal: 7m 47s\tremaining: 56.6s\n",
      "892:\tlearn: 0.0771461\ttotal: 7m 48s\tremaining: 56.1s\n",
      "893:\tlearn: 0.0771237\ttotal: 7m 49s\tremaining: 55.6s\n",
      "894:\tlearn: 0.0770841\ttotal: 7m 49s\tremaining: 55.1s\n",
      "895:\tlearn: 0.0770599\ttotal: 7m 50s\tremaining: 54.6s\n",
      "896:\tlearn: 0.0770355\ttotal: 7m 51s\tremaining: 54.1s\n",
      "897:\tlearn: 0.0769453\ttotal: 7m 51s\tremaining: 53.6s\n",
      "898:\tlearn: 0.0768197\ttotal: 7m 52s\tremaining: 53.1s\n",
      "899:\tlearn: 0.0767734\ttotal: 7m 53s\tremaining: 52.6s\n",
      "900:\tlearn: 0.0767519\ttotal: 7m 54s\tremaining: 52.1s\n",
      "901:\tlearn: 0.0766637\ttotal: 7m 54s\tremaining: 51.6s\n",
      "902:\tlearn: 0.0765983\ttotal: 7m 55s\tremaining: 51.1s\n",
      "903:\tlearn: 0.0765587\ttotal: 7m 56s\tremaining: 50.6s\n",
      "904:\tlearn: 0.0764732\ttotal: 7m 56s\tremaining: 50.1s\n",
      "905:\tlearn: 0.0764505\ttotal: 7m 57s\tremaining: 49.6s\n",
      "906:\tlearn: 0.0764277\ttotal: 7m 58s\tremaining: 49s\n",
      "907:\tlearn: 0.0763288\ttotal: 7m 59s\tremaining: 48.5s\n",
      "908:\tlearn: 0.0763052\ttotal: 7m 59s\tremaining: 48s\n",
      "909:\tlearn: 0.0762223\ttotal: 8m\tremaining: 47.5s\n",
      "910:\tlearn: 0.0761987\ttotal: 8m 1s\tremaining: 47s\n",
      "911:\tlearn: 0.0760845\ttotal: 8m 1s\tremaining: 46.5s\n",
      "912:\tlearn: 0.0760127\ttotal: 8m 2s\tremaining: 46s\n",
      "913:\tlearn: 0.0759881\ttotal: 8m 3s\tremaining: 45.5s\n",
      "914:\tlearn: 0.0759224\ttotal: 8m 3s\tremaining: 45s\n",
      "915:\tlearn: 0.0759003\ttotal: 8m 4s\tremaining: 44.4s\n",
      "916:\tlearn: 0.0758385\ttotal: 8m 5s\tremaining: 43.9s\n",
      "917:\tlearn: 0.0758127\ttotal: 8m 6s\tremaining: 43.4s\n",
      "918:\tlearn: 0.0757902\ttotal: 8m 6s\tremaining: 42.9s\n",
      "919:\tlearn: 0.0757678\ttotal: 8m 7s\tremaining: 42.4s\n",
      "920:\tlearn: 0.0757368\ttotal: 8m 8s\tremaining: 41.9s\n",
      "921:\tlearn: 0.0757128\ttotal: 8m 8s\tremaining: 41.4s\n",
      "922:\tlearn: 0.0755169\ttotal: 8m 9s\tremaining: 40.9s\n",
      "923:\tlearn: 0.0754927\ttotal: 8m 10s\tremaining: 40.3s\n",
      "924:\tlearn: 0.0754208\ttotal: 8m 11s\tremaining: 39.8s\n",
      "925:\tlearn: 0.0753988\ttotal: 8m 11s\tremaining: 39.3s\n",
      "926:\tlearn: 0.0753634\ttotal: 8m 12s\tremaining: 38.8s\n",
      "927:\tlearn: 0.0752383\ttotal: 8m 13s\tremaining: 38.3s\n",
      "928:\tlearn: 0.0751947\ttotal: 8m 13s\tremaining: 37.7s\n",
      "929:\tlearn: 0.0751471\ttotal: 8m 14s\tremaining: 37.2s\n",
      "930:\tlearn: 0.0751236\ttotal: 8m 15s\tremaining: 36.7s\n",
      "931:\tlearn: 0.0751009\ttotal: 8m 16s\tremaining: 36.2s\n",
      "932:\tlearn: 0.0750139\ttotal: 8m 16s\tremaining: 35.7s\n",
      "933:\tlearn: 0.0749917\ttotal: 8m 17s\tremaining: 35.2s\n",
      "934:\tlearn: 0.0748866\ttotal: 8m 18s\tremaining: 34.6s\n",
      "935:\tlearn: 0.0747973\ttotal: 8m 18s\tremaining: 34.1s\n",
      "936:\tlearn: 0.0747025\ttotal: 8m 19s\tremaining: 33.6s\n",
      "937:\tlearn: 0.0745872\ttotal: 8m 20s\tremaining: 33.1s\n",
      "938:\tlearn: 0.0745643\ttotal: 8m 21s\tremaining: 32.5s\n",
      "939:\tlearn: 0.0744715\ttotal: 8m 21s\tremaining: 32s\n",
      "940:\tlearn: 0.0744384\ttotal: 8m 22s\tremaining: 31.5s\n",
      "941:\tlearn: 0.0744151\ttotal: 8m 23s\tremaining: 31s\n",
      "942:\tlearn: 0.0743474\ttotal: 8m 23s\tremaining: 30.5s\n",
      "943:\tlearn: 0.0742691\ttotal: 8m 24s\tremaining: 29.9s\n",
      "944:\tlearn: 0.0742475\ttotal: 8m 25s\tremaining: 29.4s\n",
      "945:\tlearn: 0.0742255\ttotal: 8m 26s\tremaining: 28.9s\n",
      "946:\tlearn: 0.0741951\ttotal: 8m 26s\tremaining: 28.4s\n",
      "947:\tlearn: 0.0741734\ttotal: 8m 27s\tremaining: 27.8s\n",
      "948:\tlearn: 0.0741517\ttotal: 8m 28s\tremaining: 27.3s\n",
      "949:\tlearn: 0.0740742\ttotal: 8m 28s\tremaining: 26.8s\n",
      "950:\tlearn: 0.0739977\ttotal: 8m 29s\tremaining: 26.3s\n",
      "951:\tlearn: 0.0739754\ttotal: 8m 30s\tremaining: 25.7s\n",
      "952:\tlearn: 0.0737655\ttotal: 8m 31s\tremaining: 25.2s\n",
      "953:\tlearn: 0.0737425\ttotal: 8m 31s\tremaining: 24.7s\n",
      "954:\tlearn: 0.0737186\ttotal: 8m 32s\tremaining: 24.1s\n",
      "955:\tlearn: 0.0736971\ttotal: 8m 33s\tremaining: 23.6s\n",
      "956:\tlearn: 0.0736395\ttotal: 8m 33s\tremaining: 23.1s\n",
      "957:\tlearn: 0.0736047\ttotal: 8m 34s\tremaining: 22.6s\n",
      "958:\tlearn: 0.0735833\ttotal: 8m 35s\tremaining: 22s\n",
      "959:\tlearn: 0.0735610\ttotal: 8m 36s\tremaining: 21.5s\n",
      "960:\tlearn: 0.0735376\ttotal: 8m 36s\tremaining: 21s\n",
      "961:\tlearn: 0.0735098\ttotal: 8m 37s\tremaining: 20.4s\n",
      "962:\tlearn: 0.0734869\ttotal: 8m 38s\tremaining: 19.9s\n",
      "963:\tlearn: 0.0734067\ttotal: 8m 39s\tremaining: 19.4s\n",
      "964:\tlearn: 0.0733854\ttotal: 8m 39s\tremaining: 18.9s\n",
      "965:\tlearn: 0.0732831\ttotal: 8m 40s\tremaining: 18.3s\n",
      "966:\tlearn: 0.0732280\ttotal: 8m 41s\tremaining: 17.8s\n",
      "967:\tlearn: 0.0732063\ttotal: 8m 41s\tremaining: 17.3s\n",
      "968:\tlearn: 0.0731827\ttotal: 8m 42s\tremaining: 16.7s\n",
      "969:\tlearn: 0.0731191\ttotal: 8m 43s\tremaining: 16.2s\n",
      "970:\tlearn: 0.0730978\ttotal: 8m 43s\tremaining: 15.6s\n",
      "971:\tlearn: 0.0730721\ttotal: 8m 44s\tremaining: 15.1s\n",
      "972:\tlearn: 0.0730506\ttotal: 8m 45s\tremaining: 14.6s\n",
      "973:\tlearn: 0.0729278\ttotal: 8m 46s\tremaining: 14s\n",
      "974:\tlearn: 0.0728812\ttotal: 8m 46s\tremaining: 13.5s\n",
      "975:\tlearn: 0.0728602\ttotal: 8m 47s\tremaining: 13s\n",
      "976:\tlearn: 0.0728291\ttotal: 8m 48s\tremaining: 12.4s\n",
      "977:\tlearn: 0.0728071\ttotal: 8m 48s\tremaining: 11.9s\n",
      "978:\tlearn: 0.0726529\ttotal: 8m 49s\tremaining: 11.4s\n",
      "979:\tlearn: 0.0726294\ttotal: 8m 50s\tremaining: 10.8s\n",
      "980:\tlearn: 0.0726093\ttotal: 8m 51s\tremaining: 10.3s\n",
      "981:\tlearn: 0.0725861\ttotal: 8m 51s\tremaining: 9.75s\n",
      "982:\tlearn: 0.0724643\ttotal: 8m 52s\tremaining: 9.21s\n",
      "983:\tlearn: 0.0724422\ttotal: 8m 53s\tremaining: 8.67s\n",
      "984:\tlearn: 0.0724212\ttotal: 8m 53s\tremaining: 8.13s\n",
      "985:\tlearn: 0.0723403\ttotal: 8m 54s\tremaining: 7.59s\n",
      "986:\tlearn: 0.0722692\ttotal: 8m 55s\tremaining: 7.05s\n",
      "987:\tlearn: 0.0722339\ttotal: 8m 56s\tremaining: 6.51s\n",
      "988:\tlearn: 0.0722128\ttotal: 8m 56s\tremaining: 5.97s\n",
      "989:\tlearn: 0.0720841\ttotal: 8m 57s\tremaining: 5.43s\n",
      "990:\tlearn: 0.0720641\ttotal: 8m 58s\tremaining: 4.89s\n",
      "991:\tlearn: 0.0719923\ttotal: 8m 58s\tremaining: 4.35s\n",
      "992:\tlearn: 0.0719287\ttotal: 8m 59s\tremaining: 3.8s\n",
      "993:\tlearn: 0.0717940\ttotal: 9m\tremaining: 3.26s\n",
      "994:\tlearn: 0.0717333\ttotal: 9m 1s\tremaining: 2.72s\n",
      "995:\tlearn: 0.0716932\ttotal: 9m 1s\tremaining: 2.17s\n",
      "996:\tlearn: 0.0716724\ttotal: 9m 2s\tremaining: 1.63s\n",
      "997:\tlearn: 0.0716519\ttotal: 9m 3s\tremaining: 1.09s\n",
      "998:\tlearn: 0.0716012\ttotal: 9m 3s\tremaining: 544ms\n",
      "999:\tlearn: 0.0715535\ttotal: 9m 4s\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "def extract_domain(url):\n",
    "    return tldextract.extract(url).domain\n",
    "\n",
    "def predictPipelineWithExtractedDomain(train_path, test_path, target, validation=False, find_best_params=False):\n",
    "    transformer = ColumnTransformer([\n",
    "        (\"tfidf\", TfidfVectorizer(min_df=1, max_df=0.5), \"domain\"),\n",
    "        (\"count\", CountVectorizer(stop_words=stop_words), \"title\"),\n",
    "    ])\n",
    "    \n",
    "\n",
    "    test_df = pd.read_csv(test_path)\n",
    "    train_df = pd.read_csv(train_path)\n",
    "    test_df['domain'] = test_df['url'].apply(extract_domain)\n",
    "    train_df['domain'] = train_df['url'].apply(extract_domain)\n",
    "\n",
    "    train_df = train_df.dropna()\n",
    "\n",
    "    x_train = train_df\n",
    "    y_train = train_df[target]\n",
    "    del x_train[target]\n",
    "    del x_train[\"ID\"]\n",
    "\n",
    "    weights = compute_class_weight(class_weight='balanced', classes=[0, 1], y=y_train)\n",
    "    class_weights = dict(zip([0, 1], weights))\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        (\"preprocessor\", transformer),\n",
    "        (\"model\", CatBoostClassifier(class_weights=class_weights, iterations=1000))\n",
    "    ])\n",
    "\n",
    "    if validation:\n",
    "        x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.25)\n",
    "\n",
    "\n",
    "    if find_best_params:\n",
    "        param_grid = {\n",
    "            'preprocessor__tfidf__ngram_range': [(1, 3), (4, 6), (4, 8)],\n",
    "            'preprocessor__tfidf__min_df': [1, 2, 4],\n",
    "            'preprocessor__tfidf__max_df': [0.5, 0.7, 1.0]\n",
    "        }\n",
    "    \n",
    "        grid_search = GridSearchCV(pipeline, param_grid, cv=3, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "        grid_search.fit(x_train, y_train)\n",
    "\n",
    "        print(\"Best parameters found on cross-validation set:\")\n",
    "        print(grid_search.best_params_)\n",
    "        print(\"Best cross-validation score:\")\n",
    "        print(grid_search.best_score_)\n",
    "\n",
    "    pipeline.fit(x_train, y_train)\n",
    "    predicts = pipeline.predict(test_df)\n",
    "\n",
    "    if validation:\n",
    "        validation_predicts = pipeline.predict(x_valid)\n",
    "        print(classification_report(y_valid, validation_predicts))\n",
    "        print(confusion_matrix(y_valid, validation_predicts))\n",
    "        x_valid[\"true_label\"] = y_valid\n",
    "        x_valid[\"predicted_label\"] = validation_predicts\n",
    "        return x_valid\n",
    "\n",
    "    test_df[target] = predicts\n",
    "    test_df[[\"ID\", target]].to_csv(\"ml_baseline.csv\", index=False) # score 0.9626915389740173\n",
    "\n",
    "# predictPipelineWithExtractedDomain(\"train.csv\", \"test.csv\", \"label\", find_best_params=True)\n",
    "predictPipelineWithExtractedDomain(\"train.csv\", \"test.csv\", \"label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Микровывод:**\n",
    "<br>\n",
    "Score модели 0.9626915389740173. Результат несколько упал"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь попробуем добавить функцию для создания характерных слов для каждого класса, будем использовать их для постобработки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findTopValuableWords(df, target, class_number, count=5):\n",
    "    tfidf_vectorizer = TfidfVectorizer(stop_words=stop_words, lowercase=True, token_pattern=r'\\b[^\\d\\W]+\\b')\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(df[df[target] == class_number][\"title\"])\n",
    "\n",
    "    feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "    top_indices = tfidf_matrix.mean(axis=0).argsort()[:, -count:].flatten()\n",
    "\n",
    "    top_words = [feature_names[idx] for idx in top_indices]\n",
    "\n",
    "    return top_words\n",
    "\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "train_df = train_df.dropna()\n",
    "\n",
    "class1_triggers = set(findTopValuableWords(train_df, \"label\", 1, 600)[0][0]) - \\\n",
    "    set(findTopValuableWords(train_df, \"label\", 0, 3500)[0][0])\n",
    "\n",
    "class1_free_triggers = set([\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используем модель и после обрабатываем результаты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_domain(url):\n",
    "    return tldextract.extract(url).domain\n",
    "\n",
    "def predictPipelineWithExtractedDomain(train_path, test_path, target, validation=False, find_best_params=False):\n",
    "    transformer = ColumnTransformer([\n",
    "        (\"tfidf\", TfidfVectorizer(analyzer=\"char_wb\", min_df=4, max_df=0.5, ngram_range=(2, 4)), \"domain\"),\n",
    "        (\"count\", CountVectorizer(stop_words=stop_words), \"title\"),\n",
    "    ])\n",
    "    pipeline = Pipeline([\n",
    "        (\"preprocessor\", transformer),\n",
    "        (\"model\", LogisticRegression(class_weight='balanced', max_iter=1000, solver='lbfgs'))\n",
    "    ])\n",
    "\n",
    "    test_df = pd.read_csv(test_path)\n",
    "    train_df = pd.read_csv(train_path)\n",
    "    test_df['domain'] = test_df['url'].apply(extract_domain)\n",
    "    train_df['domain'] = train_df['url'].apply(extract_domain)\n",
    "\n",
    "    train_df = train_df.dropna()\n",
    "\n",
    "    x_train = train_df\n",
    "    y_train = train_df[target]\n",
    "    del x_train[target]\n",
    "    del x_train[\"ID\"]\n",
    "    test_df['title'] = test_df['title'].astype(str)\n",
    "\n",
    "    if validation:\n",
    "        x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.25)\n",
    "\n",
    "\n",
    "    if find_best_params:\n",
    "        param_grid = {\n",
    "            'preprocessor__tfidf__ngram_range': [(2, 4), (4, 6), (4, 8)],\n",
    "            'preprocessor__tfidf__min_df': [1, 2, 4],\n",
    "            'preprocessor__tfidf__max_df': [0.5, 0.7, 1.0]\n",
    "        }\n",
    "    \n",
    "        grid_search = GridSearchCV(pipeline, param_grid, cv=3, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "        grid_search.fit(x_train, y_train)\n",
    "\n",
    "        print(\"Best parameters found on cross-validation set:\")\n",
    "        print(grid_search.best_params_)\n",
    "        print(\"Best cross-validation score:\")\n",
    "        print(grid_search.best_score_)\n",
    "\n",
    "    pipeline.fit(x_train, y_train)\n",
    "    predicts = pipeline.predict(test_df)\n",
    "\n",
    "    if validation:\n",
    "        validation_predicts = pipeline.predict(x_valid)\n",
    "        print(classification_report(y_valid, validation_predicts))\n",
    "        print(confusion_matrix(y_valid, validation_predicts))\n",
    "        x_valid[\"true_label\"] = y_valid\n",
    "        x_valid[\"predicted_label\"] = validation_predicts\n",
    "        return x_valid\n",
    "    \n",
    "    # Постобработка\n",
    "    for idx, _ in enumerate(predicts):\n",
    "        title = x_test[\"title\"].iloc[idx]\n",
    "        url = x_test[\"url\"].iloc[idx]\n",
    "        if isinstance(title, str):\n",
    "            title = title.lower()\n",
    "\n",
    "            for word in (class1_triggers + class1_free_triggers):\n",
    "                if word in title:\n",
    "                    predicts[idx] = 1\n",
    "\n",
    "    test_df[target] = predicts\n",
    "    test_df[[\"ID\", target]].to_csv(\"ml_baseline.csv\", index=False) # score 0.9802919106126824\n",
    "\n",
    "predictPipelineWithExtractedDomain(\"train.csv\", \"test.csv\", \"label\", find_best_params=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Микровывод:**\n",
    "<br>\n",
    "Score модели 0.9802919106126824. Результат немного увеличился, но сильного прироста это не дало"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В итоговой модели было использовано (то, что принесло улучшение результат):\n",
    "1) Балансировка данных по классам;\n",
    "2) Подготовка фичи url;\n",
    "3) Использование TfidfVectorizer с оптимальными гиперпараметрами для url;\n",
    "4) Использование CountVectorizer с библиотечными стоп-словами;\n",
    "5) С помощью GridSearchCV были найдены лучшие гиперпараметры для модели;\n",
    "6) Был написан алгоритм постобработки на основе слов-триггеров"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
