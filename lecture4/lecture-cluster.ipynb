{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <td> <center><img src=\"images/header1.png\" width=400></center> </td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "<h1><center>Основы машинного обучения</center></h1>\n",
    "<hr>\n",
    "<h2><center>Методы обучения без учителя: кластеризация</center></h2>\n",
    "<h3><center>Ефимов Владислав</center></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-10T14:53:44.411024Z",
     "start_time": "2021-11-10T14:53:43.139546Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-10T13:10:46.766992Z",
     "iopub.status.busy": "2024-04-10T13:10:46.762311Z",
     "iopub.status.idle": "2024-04-10T13:10:46.779537Z",
     "shell.execute_reply": "2024-04-10T13:10:46.778686Z",
     "shell.execute_reply.started": "2024-04-10T13:10:46.766920Z"
    },
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-10T14:53:44.852620Z",
     "start_time": "2021-11-10T14:53:44.412259Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-10T13:10:46.781844Z",
     "iopub.status.busy": "2024-04-10T13:10:46.781689Z",
     "iopub.status.idle": "2024-04-10T13:10:46.786118Z",
     "shell.execute_reply": "2024-04-10T13:10:46.785667Z",
     "shell.execute_reply.started": "2024-04-10T13:10:46.781829Z"
    },
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('seaborn-v0_8-talk')\n",
    "plt.rcParams['figure.figsize'] = (12,8)\n",
    "\n",
    "# Для кириллицы на графиках\n",
    "font = {'family': 'Verdana',\n",
    "        'weight': 'normal'}\n",
    "plt.rc('font', **font)\n",
    "\n",
    "try:\n",
    "    from ipywidgets import interact, IntSlider, fixed, FloatSlider\n",
    "except ImportError:\n",
    "    print('Так надо')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Методы обучения без учителя (unsupervised)\n",
    "\n",
    "* В чём отличие от supervised методов?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Кластеризация\n",
    "* Уменьшение размерности\n",
    "    * Метод главных компонент\n",
    "    * Многомерное шкалирование\n",
    "    * Тематические модели\n",
    "* Поиск ассоциативных правил"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Кластеризация\n",
    "\n",
    "Основная задача кластерного анализа — разбиение исходного набора объектов на группы (кластеры) таким образом, чтобы объекты в группе были похожи друг на друга, а объекты из разных групп отличались.\n",
    "\n",
    "<center><img src=\"https://i.ytimg.com/vi/zPJtDohab-g/maxresdefault.jpg\" width=600></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Цели кластерного анализа\n",
    "\n",
    "* **Поиск структуры** в данных и её **интерпретация**\n",
    "* Поиск аномальных объектов\n",
    "* Детальный анализ отдельных кластеров\n",
    "* Формирование признаков на основе кластеризации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Use Case: Telegram Clustering Contest\n",
    "1. Traverse an input directory and parse all HTML files (articles) in it with news content\n",
    "2. Detect article language and filter out articles which are not in English or Russian\n",
    "3. Classify articles into one or several of 7 categories: society, economy, technology, sports, entertainment, science, other\n",
    "4. Filter out articles which are not news (e.g. how-tos, tips, encyclopedic content)\n",
    "5. Group articles into threads. Thread is just a collection of articles about the same event\n",
    "6. Sort articles within a thread by relevance\n",
    "7. Sort threads by importance\n",
    "\n",
    "2nd Place solution [description](https://medium.com/@alexkuznetsov/2nd-place-solution-for-telegram-data-clustering-contest-f28d55b98d30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Группы методов\n",
    "\n",
    "* Методы, основанные на прототипах\n",
    "    * Каждый кластер ассоциируется с виртуальным \"эталонным\" объектом\n",
    "* Иерархические методы\n",
    "    * Не простое разбиение, а целая иерархия\n",
    "* Плотностные методы\n",
    "    * Ищем плотные скопления точек в признаковом пространстве\n",
    "* Вероятностные методы\n",
    "    * Предполагаем, что данные порождены некоторой смесью вероятностных распределений\n",
    "* Спектральные методы\n",
    "    * Испольюзуем замечательные спектральные свойства разных матриц\n",
    "* Сеточные методы\n",
    "    * Бьем признаковое пространство на сегменты\n",
    "* ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Алгоритм [k-means](https://scikit-learn.org/stable/modules/clustering.html#k-means)\n",
    "### Неформальное [демо](https://www.naftaliharris.com/blog/visualizing-k-means-clustering/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Постановка\n",
    "\n",
    "* Дано множество объектов $X = \\{x_1, x_2, \\dots, x_N\\}$\n",
    "* Кластер $C_k \\Leftrightarrow \\text{ центроид } \\mu_k$\n",
    "* Объект $x_i \\in C_k \\Leftrightarrow \\mu_k = \\arg \\min\\limits_{\\mu_j} \\|x_i - \\mu_j \\|^2$\n",
    "* Надо найти такое разбиение на $K$ кластеров, чтобы минимизировать функционал:\n",
    "$$ L(C) = \\sum_{k=1}^K\\sum_{i\\in C_k} ||x_i - \\mu_k||^2 \\rightarrow \\min\\limits_C $$\n",
    "$$\\mu_k = \\frac{1}{|C_k|} \\sum _{x_n \\in C_k} x_n$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Метод $k$-средних является итеративным алгоритмом разбиения множества объектов на $K$ кластеров "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Описание алгоритма\n",
    "1. Выбрать $K$ начальных центроидов случайным образом  $\\rightarrow \\mu_k, \\ k=1\\dots K$\n",
    "2. Для каждой точки из датасета присвоить кластер, соответствующий ближайшему центроиду:\n",
    "$$C_k = \\{x_n : ||x_n - \\mu_k||^2 \\leq ||x_n - \\mu_l||^2 \\quad \\forall l \\neq k \\} $$\n",
    "3. Обновить центроиды: \n",
    "$$\\mu_k = \\frac{1}{|C_k|} \\sum _{x_n \\in C_k} x_n$$\n",
    "4. Повторять 2 и 3 до тех пор, пока изменения перестанут быть существенными \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src='images/Kmeans_animation.gif' width=500></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Основные факторы\n",
    "* Начальная инициализация центроидов\n",
    "* Количество кластеров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Kак выбрать K?\n",
    "\n",
    "* Не пользоваться обычным k-means (X-means, ik-means)\n",
    "* Посмотреть на меры качества кластеризации\n",
    "* Воспользоваться эвристиками"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Elbow Method («метод локтя»)\n",
    "\n",
    "* Критерий минимизации k-means:\n",
    "$$ L(C) = \\sum_{k=1}^K\\sum_{i\\in C_k} ||x_i - \\mu_k||^2 \\rightarrow \\min\\limits_C $$\n",
    "* Давайте возьмём все возможные $K$, для каждого запустим алгоритм, посчитаем на результате $L(C)$ и выберем минимум!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Ничего не выйдет... Почему?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-10T14:53:45.805294Z",
     "start_time": "2021-11-10T14:53:44.853653Z"
    },
    "code_folding": [
     3,
     20,
     34,
     40
    ],
    "execution": {
     "iopub.execute_input": "2024-04-10T13:10:46.787313Z",
     "iopub.status.busy": "2024-04-10T13:10:46.787163Z",
     "iopub.status.idle": "2024-04-10T13:10:47.975058Z",
     "shell.execute_reply": "2024-04-10T13:10:47.974612Z",
     "shell.execute_reply.started": "2024-04-10T13:10:46.787299Z"
    },
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "X, y = make_blobs(n_samples=500,\n",
    "                  n_features=2,\n",
    "                  centers=4,\n",
    "                  cluster_std=1,\n",
    "                  center_box=(-10.0, 10.0),\n",
    "                  shuffle=True,\n",
    "                  random_state=1) \n",
    "\n",
    "\n",
    "crit = []\n",
    "\n",
    "for k in range(2, 8):\n",
    "    kmeans = KMeans(n_clusters=k, random_state=1, n_init='auto').fit(X)\n",
    "    crit.append(np.sqrt(kmeans.inertia_))\n",
    "    \n",
    "def elbow_demo(k=2):\n",
    "    \n",
    "    X, y = make_blobs(n_samples=500,\n",
    "                  n_features=2,\n",
    "                  centers=4,\n",
    "                  cluster_std=1,\n",
    "                  center_box=(-10.0, 10.0),\n",
    "                  shuffle=True,\n",
    "                  random_state=1) \n",
    "    \n",
    "    kmeans = KMeans(n_clusters=k, random_state=1, n_init='auto').fit(X)\n",
    "    \n",
    "    fig, ax = plt.subplots(1,2)\n",
    "    \n",
    "    ax[0].scatter(X[:,0], X[:,1], c=kmeans.labels_)\n",
    "    \n",
    "    ax[0].scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1],\n",
    "                  marker='o', c=\"white\", alpha=1, s=200)\n",
    "    \n",
    "    ax[0].set_xlabel('$x_1$')\n",
    "    ax[0].set_ylabel('$x_2$')\n",
    "\n",
    "    for i, c in enumerate(kmeans.cluster_centers_):\n",
    "        ax[0].scatter(c[0], c[1], marker='$%d$' % i, alpha=1, s=50)\n",
    "        \n",
    "    ax[1].plot(range(2,8), crit, marker='s')\n",
    "    \n",
    "    ax[1].set_xlabel('$k$')\n",
    "    ax[1].set_ylabel('$L^{(k)}(C)$')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Итоговая эвристика\n",
    "\n",
    "* Выбирают такое $k$, после которого функционал $L(C)$ уменьшается не слишком быстро.\n",
    "* Чуть более формально, значение функционала невелико:\n",
    "$$ D(k) = \\frac{|L^{(k)}(C) - L^{(k+1)}(C)|}{|L^{(k-1)}(C) - L^{(k)}(C)|} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-10T15:36:52.453729Z",
     "start_time": "2021-11-10T15:36:52.227961Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-10T13:10:47.976914Z",
     "iopub.status.busy": "2024-04-10T13:10:47.976730Z",
     "iopub.status.idle": "2024-04-10T13:10:48.240054Z",
     "shell.execute_reply": "2024-04-10T13:10:48.239739Z",
     "shell.execute_reply.started": "2024-04-10T13:10:47.976894Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edff657518aa453a841a0652a90de66a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=2, description='k', max=8, min=2), Output()), _dom_classes=('widget-inte…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot = interact(elbow_demo, k=IntSlider(min=2,max=8,step=1,value=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Важно!\n",
    "* Эвристика и меры качества кластеризации носят лишь рекомендательный характер!\n",
    "* Если они ничего не дают, то лучше ориентироваться на свои знания в предметной области.\n",
    "* Или выжать из полученной кластеризации максимум.\n",
    "    * *3 из 5 полученных кластеров интерпретируются — и то хорошо.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Начальная инициализация центройдов\n",
    "* Выбрать координаты $K$ случайных объектов из датасета.\n",
    "    * Производить случайные запуски много раз и выбрать наиболее оптимальную инициализацию.\n",
    "* Использовать результат другой кластеризации на $K$ кластеров.\n",
    "* k-means++."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### K-means++\n",
    "* Первый центроид выбираем случайным образом из объектов датасета.\n",
    "* Для каждой точки рассчитываем расстояние $d_{\\min}(x_i) = \\min_{\\mu_j} \\|x_i - \\mu_j\\|^2$.\n",
    "* Точка назначается следующим центроидом с вероятностью $p(x_i) \\propto d_{\\min}(x_i)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-10T14:53:46.178115Z",
     "start_time": "2021-11-10T14:53:46.171963Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-10T13:10:48.240723Z",
     "iopub.status.busy": "2024-04-10T13:10:48.240579Z",
     "iopub.status.idle": "2024-04-10T13:10:48.246407Z",
     "shell.execute_reply": "2024-04-10T13:10:48.246148Z",
     "shell.execute_reply.started": "2024-04-10T13:10:48.240712Z"
    },
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "def demo_kmpp(iters=1):\n",
    "\n",
    "    X, y = make_blobs(n_samples=550, cluster_std=1.5, n_features=2, centers=5, random_state=12345)\n",
    "\n",
    "    X_grid1, X_grid2 = np.meshgrid(np.linspace(-12, 18, 500),\n",
    "                                   np.linspace(-11, 8, 500))\n",
    "\n",
    "    XX = np.c_[X_grid1.flatten(), X_grid2.flatten()]\n",
    "    np.random.seed(1)\n",
    "    centroids = np.empty((0, 2))\n",
    "\n",
    "    for i in range(iters):\n",
    "        if i == 0:\n",
    "            d = np.ones_like(y, dtype=float)\n",
    "        else:\n",
    "            d = pairwise_distances(X, centroids, metric='euclidean').min(axis=1)\n",
    "        weights = d/d.sum()\n",
    "\n",
    "        centroid_idx = np.random.choice(X.shape[0], size=1, replace=False, p=weights)[0]\n",
    "        centroids = np.r_[centroids, X[centroid_idx, np.newaxis]]\n",
    "\n",
    "    d_grid = pairwise_distances(XX, centroids, metric='euclidean').min(axis=1)\n",
    "\n",
    "    d_grid = d_grid.reshape(X_grid1.shape)\n",
    "    d_grid = d_grid/d_grid.max()\n",
    "\n",
    "    levels = np.linspace(0, 1, 100)\n",
    "\n",
    "    plt.contourf(X_grid1, X_grid2, d_grid, cmap=plt.cm.Blues, alpha=0.7, levels=levels)\n",
    "    plt.scatter(X[:, 0], X[:, 1], s=100)\n",
    "\n",
    "    centers = centroids\n",
    "    \n",
    "    plt.scatter(centers[:, 0], centers[:, 1], marker='o',\n",
    "                c=\"white\", alpha=1, s=500, edgecolor='k')\n",
    "\n",
    "    for i, c in enumerate(centers):\n",
    "        plt.scatter(c[0], c[1], marker='$%d$' % (i+1), alpha=1,\n",
    "                    s=100, edgecolor='k')\n",
    "\n",
    "    plt.xlabel('$x_1$', fontsize=15)\n",
    "    plt.ylabel('$x_2$', fontsize=15)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.axis('equal')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-10T15:43:54.718435Z",
     "start_time": "2021-11-10T15:43:54.346295Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-10T13:10:48.246832Z",
     "iopub.status.busy": "2024-04-10T13:10:48.246744Z",
     "iopub.status.idle": "2024-04-10T13:10:48.604798Z",
     "shell.execute_reply": "2024-04-10T13:10:48.604474Z",
     "shell.execute_reply.started": "2024-04-10T13:10:48.246823Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d92ecbcd0994f2dae632085b79a920f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='iters', max=6, min=1), Output()), _dom_classes=('widget-…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.demo_kmpp(iters=1)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interact(demo_kmpp, iters=IntSlider(min=1,max=6,step=1,value=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Резюме\n",
    "\n",
    "* Метод k-средних — жадный итеративный алгоритм.\n",
    "* Зависит от начальных центроидов и их количества.\n",
    "\n",
    "#### Преимущества\n",
    "* Прост.\n",
    "* Имеет множество модификаций.\n",
    "* Интерпретация кластеров через центроиды."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Недостатки\n",
    "\n",
    "* Подразумевает выпуклые кластеры.\n",
    "<center><img src='images/kmeans_2moons.png' width=800></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Почти всегда на выходе будет k кластеров.\n",
    "<center><img src='images/kmeans_digits.png' width=800></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Иерархические алгоритмы: [Agglomerative Clustering](https://scikit-learn.org/stable/modules/clustering.html#hierarchical-clustering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Основная идея\n",
    "\n",
    "* Идём снизу вверх, вначале все точки в своём кластере.\n",
    "* На каждом шаге объединяем два ближайших кластера.\n",
    "* Продолжаем, пока не дойдём до корня.\n",
    "\n",
    "<center><img src='images/sphx_glr_plot_agglomerative_dendrogram_001.png'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Что значит ближайшие кластеры, как мерить расстояние?\n",
    "Есть несколько стратегий, которые можно использовать для объединения кластеров:\n",
    "1. Ward — минимизирует расстояния между точками в одном кластере: $\\sum_{x, y \\in c} ||x - y||^2 \\to \\min$\n",
    "2. Complete (maximum) linkage — минимизирует максимальное расстояние между точками разных кластеров: $$\\min_{c_1 \\neq c_2 \\in C} \\max_{x \\in c_1, y \\in c_2} \\rho(x, y)$$\n",
    "3. Average linkage — минимизирует среднее расстояние между точками разных кластеров: $$\\min_{c_1 \\neq c_2 \\in C} \\frac{1}{|c_1|}\\sum_{x \\in c_1} \\frac{1}{|c_2|}\\sum_{y \\in c_2} \\rho(x, y)$$\n",
    "4. Single linkage — минимизирует расстояние между ближайшими точками разных кластеров: $$\\min_{c_1 \\neq c_2 \\in C} \\min_{x \\in c_1, y \\in c_2} \\rho(x, y)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Примеры применения разных подходов\n",
    "<center><img src='images/sphx_glr_plot_linkage_comparison_001.png'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Алгоритмы, основанные на плотности: [DBSCAN](https://scikit-learn.org/stable/modules/clustering.html#dbscan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Хотелось бы...\n",
    "\n",
    "Получить кластеры высокой плотности, разделённые участками низкой плотности\n",
    "\n",
    "<center><img src='images/dbscan.png'></center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Основная идея\n",
    "\n",
    "* Для каждой точки кластера её окрестность заданного радиуса $\\epsilon$ должна содержать не менее некоторого числа точек `min_pts`. \n",
    "* C такой точки можно начать расширение «плотного» кластера:\n",
    "    * то есть каждая точка в $\\epsilon$ окрестности будет добавляться в кластер.\n",
    "    * её соседи тоже будут проверяться на критерий `min_pts`.\n",
    "* Расширение текущего кластера закончится, когда объекты перестанут удовлетворять условию `min_pts`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Demo\n",
    "Иногда вместо тысячи слов лучше один раз посмотреть, как алгоритм работает. Но с небольшими комментариями.\n",
    "\n",
    "\n",
    "[Тык](https://www.naftaliharris.com/blog/visualizing-dbscan-clustering/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Типы точек\n",
    "* Core point: точки, в $\\varepsilon$-окрестности которых $\\ge$ `min_pts` точек.\n",
    "* Border point: не core, но содержит хотя бы 1 core-точку в $\\varepsilon$-окрестности.\n",
    "* Noise point: всё остальное.\n",
    "<center><img src='images/dbscan_points_types.png'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## DBSCAN\n",
    "\n",
    "```{C}\n",
    "1.function dbscan(X, eps, min_pts):\n",
    "2.\tinitialize NV = X # not visited objects\t\n",
    "3.\tfor x in NV:\n",
    "4.\t\tremove(NV, x) # mark as visited\n",
    "5.\t\tnbr = neighbours(x, eps) # set of neighbours\n",
    "6.\t\tif nbr.size < min_pts:\n",
    "7.\t\t\tmark_as_noise(x)\n",
    "8.\t\telse:\n",
    "9.\t\t\tC = new_cluster() \n",
    "10.\t\t\texpand_cluster(x, nbr, C, eps, min_pts, NV)\n",
    "11.\t\t\tyield C\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "##  expand_cluster\n",
    "\n",
    "```{C}\n",
    "1. function expand_cluster(x, nbr, C, eps, min_pts, NV):\n",
    "2.\tadd(x, C)\n",
    "3.\tfor x1 in nbr:\n",
    "4.\t\tif x1 in NV: # object not visited\n",
    "5.\t\t\tremove(NV, x1) # mark as visited\n",
    "6.\t\t\tnbr1 = neighbours(x1, eps)\n",
    "7.\t\t\tif nbr1.size >= min_pts:\n",
    "8.\t\t\t\t# join sets of neighbours\n",
    "9.\t\t\t\tmerge(nbr, nbr_1)\n",
    "10.\t\tif x1 not in any cluster:\n",
    "11.\t\t\tadd(x1, C)\t\t\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-10T14:54:03.959621Z",
     "start_time": "2021-11-10T14:54:03.947592Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-10T13:10:48.605415Z",
     "iopub.status.busy": "2024-04-10T13:10:48.605323Z",
     "iopub.status.idle": "2024-04-10T13:10:48.610288Z",
     "shell.execute_reply": "2024-04-10T13:10:48.610016Z",
     "shell.execute_reply.started": "2024-04-10T13:10:48.605406Z"
    },
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "\n",
    "data = np.loadtxt('data/flame.txt')\n",
    "X_data = data[:, :2]\n",
    "\n",
    "def dbscan_demo(eps=1, min_pts=5):\n",
    "    \n",
    "    dbscan = DBSCAN(eps=eps, min_samples=min_pts).fit(X_data)\n",
    "    \n",
    "    labels = dbscan.labels_\n",
    "    \n",
    "    plt.figure(figsize=(7,5))\n",
    "    plt.scatter(X_data[:,0], X_data[:, 1], c=labels)\n",
    "    \n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-10T14:54:05.147604Z",
     "start_time": "2021-11-10T14:54:05.027900Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-10T13:10:48.610765Z",
     "iopub.status.busy": "2024-04-10T13:10:48.610672Z",
     "iopub.status.idle": "2024-04-10T13:10:48.699694Z",
     "shell.execute_reply": "2024-04-10T13:10:48.699365Z",
     "shell.execute_reply.started": "2024-04-10T13:10:48.610756Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8bc83a2a3ff492dad3d2b4d89ea03cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=1.0, description='eps', max=10.0, min=0.1, step=0.05), IntSlider(value…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.dbscan_demo(eps=1, min_pts=5)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interact(dbscan_demo, eps=FloatSlider(min=0.1, max=10, step=0.05, value=1), min_pts=IntSlider(min=2, max=15, step=1, value=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Итог\n",
    "\n",
    "#### Преимущества\n",
    "* Не требует $K$\n",
    "* Кластеры произвольной формы\n",
    "* Учитывает выбросы\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Недостатки\n",
    "* Не работает при различных плотностях кластеров\n",
    "* Не всегда выявит кластеры"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src='images/diff-dens.png'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Алгоритмы, основанные на плотности: [HDBSCAN](https://scikit-learn.org/stable/modules/clustering.html#hdbscan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Мотивация\n",
    "Хотелось бы всё-таки искать кластеры среди точек разной плотности."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Модифицируем расстояние\n",
    "\n",
    "\n",
    "* По сути, мы пытаемся найти «островки» повышенной плотности среди всего\n",
    "разреженного «моря» точек.\n",
    "* Давайте разнесём наше «море» и «острова» подальше друг от друга, то есть\n",
    "сделаем «море» ещё более разреженным, а точки внутри «островов» не будем\n",
    "трогать.\n",
    "* Введём новое расстояние доступности (Reachability):\n",
    "$$d_{\\mathrm{mreach-}k}(a,b) = \\max \\{\\mathrm{core}_k(a), \\mathrm{core}_k(b), d(a,b) \\},$$\n",
    "где $\\mathrm{core}_k(a)$ — core-расстояние точки a, как в DBSCAN, $d(a,b)$ — оригинальное расстояние между точками.\n",
    "\n",
    "<center><img src='images/distance3.svg'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src='images/distance4a.svg'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src='images/distance5.svg'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Минимальное остовное дерево\n",
    "\n",
    "* Строим по полученным новым расстояниям граф (вершина — исходная точка, ребро соединяет две точки с весом $d_{\\mathrm{mreach-}k}(a,b)$).\n",
    "* Получим большой граф, который надо уменьшить. Можно при построении сразу выкидывать ребра больше некоторого $\\epsilon$.\n",
    "* Построим минимальное остовное дерево, например, с помощью [алгоритма Прима](https://ru.wikipedia.org/wiki/Алгоритм_Прима).\n",
    "\n",
    "<center><img src='images/how_hdbscan_works_10_1.webp'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Строим иерархию\n",
    "\n",
    "* Идём снизу вверх, как обычно, а именно от самых коротких к самым длинным рёбрам.\n",
    "* Объединяем рёбра в кластеры, используя структуру Union-Find.\n",
    "\n",
    "<center><img src='images/how_hdbscan_works_12_1.webp'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Конденсируем дерево\n",
    "\n",
    "* Идём сверху вниз и анализируем ветвления.\n",
    "* Точки либо просто отваливаются (один из кластеров < min_cluster_size), либо образуют два полноценных кластера.\n",
    "\n",
    "<center><img src='images/how_hdbscan_works_15_1.webp'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Выделяем кластеры\n",
    "\n",
    "* Хотим видеть в качестве кластеров наиболее долгоживущие.\n",
    "* Не хотим учитывать кластеры с малым временем жизни: это, скорее всего, какие-то артефакты.\n",
    "* Если выбираем вершину в качестве кластера, то мы не можем далее выбрать её «потомков» в качестве отдельных кластеров.\n",
    "* Условно считаем площади этих «сосулек». Если площадь «детей» больше площади «родителя», то разделение правомерно, и мы считаем площадью «родителя» сумму его «детей». Иначе разделение плохое — склеиваем обратно.\n",
    "\n",
    "<center><img src='images/how_hdbscan_works_18_1.webp'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Пример на данных\n",
    "<center><img src='images/how_hdbscan_works_20_1.webp'></center>\n",
    "\n",
    "Более подробно можно почитать [официальной документации](https://hdbscan.readthedocs.io/en/latest/how_hdbscan_works.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Итог\n",
    "\n",
    "#### Преимущества\n",
    "* Не требует $K$\n",
    "* Кластеры произвольной формы\n",
    "* Учитывает выбросы\n",
    "* Работает при различных плотностях кластеров\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Недостатки\n",
    "* Не всегда выявит кластеры"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Gaussian Mixture](https://scikit-learn.org/stable/modules/mixture.html#gaussian-mixture-models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Идея\n",
    "\n",
    "* Предположим, что наши данные — это смесь данных из разных гауссовых распределений.\n",
    "* Тогда можем попытаться оценить параметры этих распределений, основываясь на ММП:\n",
    "$${ L({\\boldsymbol {\\theta }};\\mathbf {X} )=p(\\mathbf {X} \\mid {\\boldsymbol {\\theta }})=\\int p(\\mathbf {X} ,\\mathbf {Z} \\mid {\\boldsymbol {\\theta }})\\,d\\mathbf {Z} =\\int p(\\mathbf {X} \\mid \\mathbf {Z} ,{\\boldsymbol {\\theta }})p(\\mathbf {Z} \\mid {\\boldsymbol {\\theta }})\\,d\\mathbf {Z} }$$\n",
    "* Для оценки параметров распределений используется EM-алгоритм.\n",
    "* Можно думать об алгоритме как о некотором обобщении k-means.\n",
    "\n",
    "<center><img src='images/sphx_glr_plot_gmm_pdf_001.png'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Параметры алгоритма\n",
    "\n",
    "* n_components: количество компонент (распределений), из которых состоят данные.\n",
    "* covariance_type: тип ковариаций (задает ограничения на форму).\n",
    "* init_params: инициализация параметров (лучше оставлять по умолчанию).\n",
    "\n",
    "<center>\n",
    "    <img src='images/sphx_glr_plot_gmm_covariances_001.png'>\n",
    "    <img src='images/sphx_glr_plot_gmm_init_001.png'>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Итог\n",
    "\n",
    "#### Преимущества\n",
    "* Один из самых быстрых алгоритмов.\n",
    "* Может работать с разными формами гауссовых распределений.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Недостатки\n",
    "* Нужно знать параметр $k$.\n",
    "* Ограничение на «гауссовость» данных.\n",
    "* Может расходиться на компонентах с очень высокой плотностью."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Spectral Clustering](https://scikit-learn.org/stable/modules/clustering.html#spectral-clustering)\n",
    "## Идея, граф на данных\n",
    "\n",
    "* Вернёмся к идее (DBSCAN), где наши точки объединяются в один кластер, если лежат в некоторой окрестности друг друга.\n",
    "* Тогда мы можем построить граф на наших данных: вершины — точки, рёбра проводим между точкой и всеми точками в её $\\epsilon$ окретсности.\n",
    "* Альтернативно можем строить граф из ближайших соседей (соединяем вершину ребром с $k$ ближайшими соседями).\n",
    "* Ещё один вариант: можно построить полный граф, задав вес ребра в зависимости от расстояния между точками. Можно для разреживания данных отрезать веса меньше некоторого $\\epsilon$. Часто в качестве веса берут гауссово ядро (RBF):\n",
    "$$S(x_i, x_j) = \\exp\\left( - \\frac{||x_i - x_j||^2}{2 \\sigma^2} \\right)$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Алгоритм\n",
    "\n",
    "* Имея граф, мы можем применить к нему алгоритм спектральной кластеризации.\n",
    "* В общем случае по матрице смежности мы должны получить её лапласиан. Однако в случае формирования матрицы методом RBF или ближайшими соседями можно использовать напрямую полученную матрицу.\n",
    "* В итоге для полученной матрицы мы ищем $k$ собственных векторов.\n",
    "* Проецируем данные на полученные векторы, то есть получаем представление наших данных в пространстве меньшей размерности ($k$).\n",
    "* Применяем стандартный алгоритм кластеризации (например, k-means)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Итог\n",
    "\n",
    "#### Преимущества\n",
    "* Хорошо подходит для невыпуклых данных.\n",
    "* Размечает все точки.\n",
    "* По сравнению с DBSCAN, HDBSCAN может находить более интересные кластеры, нежадный алгоритм.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Недостатки\n",
    "* Нужно знать параметр $k$.\n",
    "* Может занять много времени, особенно если данные не разреженные."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Есть ещё много разных алгоритмов\n",
    "<center><img src='images/sphx_glr_plot_cluster_comparison_001.png'></center>\n",
    "\n",
    "Начать можно [отсюда](https://scikit-learn.org/stable/modules/clustering.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Оценка качества кластеризации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Оценка качества кластеризации при известном ground truth\n",
    "\n",
    "Пусть $\\hat{\\pi}$ — это полученное разбиение на кластеры, а $\\pi^*$ — ground truth. \n",
    "\n",
    "<center><img src='images/sphx_glr_plot_iris_dataset_001.png' width=800></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Adjusted Rand Index\n",
    "\n",
    "$$ \\text{Rand}(\\hat{\\pi},\\pi^*) = \\frac{a + d}{a + b + c + d} \\text{,}$$\n",
    "где \n",
    "* $a$ — количество пар объектов, находящихся в одинаковых кластерах в $\\hat{\\pi}$ и\n",
    "$\\pi^*$,\n",
    "* $b$ ($c$) — количество пар объектов в одном и том же кластере в  $\\hat{\\pi}$ ($\\pi^*$), но в разных в  $\\pi^*$ ($\\hat{\\pi}$),\n",
    "* $d$ — количество пар объектов в разных кластерах в $\\hat{\\pi}$ и $\\pi^*$.\n",
    "\n",
    "<center><img src='images/rand1.png' width=700></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Индекс Жаккара\n",
    "$$ Jac(\\hat{\\pi}, \\pi^*) = \\frac{a}{a + b + c}$$\n",
    "\n",
    "#### Точность, полнота и F-мера\n",
    "$$ Precision(\\hat{\\pi}, \\pi^*) = \\frac{a}{a + b} $$\n",
    "$$ Recall(\\hat{\\pi}, \\pi^*) = \\frac{a}{a + c} $$\n",
    "$$ F-measure(\\hat{\\pi}, \\pi^*) = \\frac{2Precision \\cdot Recall}{Precision + Recall} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Меры валидности кластеров (без ground truth)\n",
    "\n",
    "* Измеряют полученые разбиения по отношению к качествам хорошей кластеризации:\n",
    "    * Компактность объектов внутри кластера.\n",
    "    * Разделимость кластеров друг от друга.\n",
    "    \n",
    "Про различные меры качества кластризации и меры валидности кластеров в sklearn можно почитать [тут](https://scikit-learn.org/stable/modules/clustering.html#clustering-evaluation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "##### Критерий silhouette\n",
    "\n",
    "Пусть дана кластеризация в $K$ кластеров, и объект $i$ попал в $C_k$:\n",
    "\n",
    "* $a(i)$ — среднее расстояние от $i$ объекта до объектов из $C_k$.\n",
    "* $b(i) = min_{j \\neq k} b_j(i)$,  где $b_j(i)$ — среднее расстояние от $i$ объекта до объектов из $C_j$.\n",
    "* Критерий:\n",
    "$$\n",
    "silhouette(i) = \\frac{b(i) - a(i)}{\\max(a(i), b(i))}.\n",
    "$$\n",
    "Средний silhouette для всех точек из $\\mathbf{X}$ является критерием качества кластеризации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src='images/sil1.png'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src='images/sil2.png'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Важно! (Eщё раз :))\n",
    "* Эвристики и меры качества кластеризации носят лишь рекомендательный характер!\n",
    "* Если они ничего не дают, то лучше ориентироваться на свои знания в предметной области.\n",
    "* Или \"выжать\" из полученной кластеризации максимум.\n",
    "    * *3 из 5 полученных кластеров интерпретируются — и то хорошо.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Литература\n",
    "* [Mohammed J. Zaki. Data Mining and Analysis: Fundamental Concepts and Algorithms. Ch. 3](https://www.amazon.com/Data-Mining-Analysis-Fundamental-Algorithms/dp/0521766338)\n",
    "* [Jure Leskovec, Anand Rajaraman, Jeffrey D. Ullman. Mining of Massive Datasets. Ch. 7](http://www.mmds.org/)\n",
    "* [Andrew R. Webb, Keith D. Copsey. Statistical Pattern Recognition. Ch. 11](http://eu.wiley.com/WileyCDA/WileyTitle/productCd-0470682272.html)\n",
    "* [A Tutorial on Spectral Clustering](https://arxiv.org/pdf/0711.0189.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Вопросы?\n",
    "\n",
    "### Пожалуйста, напишите отзыв о лекции"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "livereveal": {
   "theme": "serif",
   "transition": "concave"
  },
  "nav_menu": {},
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "513px",
    "width": "253px"
   },
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "toc_position": {
   "height": "32px",
   "left": "9px",
   "right": "1379px",
   "top": "33px",
   "width": "212px"
  },
  "widgets": {
   "state": {
    "54e80d57f79b4bfc934a2b84cf5fe7ba": {
     "views": [
      {
       "cell_index": 47
      }
     ]
    },
    "5fb17a3592634a4fba98446dacd6db43": {
     "views": [
      {
       "cell_index": 11
      }
     ]
    },
    "6f6f6ce7b81743308b92966f225862a8": {
     "views": [
      {
       "cell_index": 34
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
